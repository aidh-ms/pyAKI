{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pyAKI","text":"<p> A Python package to detect AKI within time series data. </p> <p>Source Code: https://github.com/aidh-ms/pyAKI Paper: https://doi.org/10.1371/journal.pone.0315325</p> <p>The goal of this package is to establish well tested, comprehensive functions for the detection of Acute Kidney Injury (AKI) in time series data, according to the Kidney Disease Improving Global Outcomes (KDIGO) Criteria, established in 2012 <sup>1</sup>. </p> <ol> <li> <p>Improving Global Outcomes (KDIGO) Acute Kidney Injury Work Group. KDIGO Clinical Practice Guideline for Acute Kidney Injury. Kidney inter., Suppl. 2012; 2: 1\u2013138.\u00a0\u21a9</p> </li> </ol>"},{"location":"getting_started/basic_usage/","title":"Basic Usage","text":"<p>An example of the basic usage is shown below. depending on your data you can specify the different datasets with the corresponding types. For the required columns please refer to the api reference documentation. After creating the analyser, you can analyse the data by calling the <code>process_stays</code> to process all patients. to process a single patient, you can use the <code>process_stay</code> method. please specify the patient id (<code>stay_id</code>) when analysing for a single patient.</p> <p>the result will be a dataset containing several columns with the suffix <code>stage</code> containing the stages corresponding to the different probes. the overall <code>stage</code> is found in the stage column.</p> <pre><code>import pandas as pd\n\nfrom pyaki.probes import Dataset, DatasetType\nfrom pyaki.kdigo import Analyser\n\ndata = [\n    Dataset(DatasetType.URINEOUTPUT, pd.DataFrame()),\n    Dataset(DatasetType.CREATININE, pd.DataFrame()),\n    Dataset(DatasetType.DEMOGRAPHICS, pd.DataFrame()),\n    Dataset(DatasetType.RRT, pd.DataFrame()),\n]\n\nanalyser = Analyser(data)\nresults: pd.DataFrame =  analyser.process_stays()\n</code></pre>"},{"location":"getting_started/citing/","title":"Citing","text":"<p>If you are a researcher and use this project as part of your research, please feel free to cite our publication.</p>"},{"location":"getting_started/citing/#paper","title":"Paper","text":"<p>Our paper has been published in PLOS One. You can use the following Bibtex to cite it.</p> <pre><code>@article{10.1371/journal.pone.0315325,\n    doi = {10.1371/journal.pone.0315325},\n    author = {Porschen, Christian AND Ernsting, Jan AND Brauckmann, Paul AND Weiss, Raphael AND W\u00fcrdemann, Till AND Booke, Hendrik AND Amini, Wida AND Maidowski, Ludwig AND Risse, Benjamin AND Hahn, Tim AND von Groote, Thilo},\n    journal = {PLOS ONE},\n    publisher = {Public Library of Science},\n    title = {pyAKI\u2014An open source solution to automated acute kidney injury classification},\n    year = {2025},\n    month = {01},\n    volume = {20},\n    url = {https://doi.org/10.1371/journal.pone.0315325},\n    pages = {1-14},\n    abstract = {Objective Acute kidney injury (AKI) is a frequent complication in critically ill patients, affecting up to 50% of patients in the intensive care units. The lack of standardized and open-source tools for applying the Kidney Disease Improving Global Outcomes (KDIGO) criteria to time series, requires researchers to implement classification algorithms of their own which is resource intensive and might impact study quality by introducing different interpretations of edge cases. This project introduces pyAKI, an open-source pipeline addressing this gap by providing a comprehensive solution for consistent KDIGO criteria implementation.   Materials and methods The pyAKI pipeline was developed and validated using a subset of the Medical Information Mart for Intensive Care (MIMIC)-IV database, a commonly used database in critical care research. We constructed a standardized data model in order to ensure reproducibility. PyAKI implements the Kidney Disease: Improving Global Outcomes (KDIGO) guideline on AKI diagnosis. After implementation of the diagnostic algorithm, using both serum creatinine and urinary output data, pyAKI was tested on a subset of patients and diagnostic accuracy was compared in a comparative analysis against annotations by physicians.   Results Validation against expert annotations demonstrated pyAKI\u2019s robust performance in implementing KDIGO criteria. Comparative analysis revealed its ability to surpass the quality of human labels with an accuracy of 1.0 in all categories.   Discussion The pyAKI pipeline is the first open-source solution for implementing KDIGO criteria in time series data. It provides a standardized data model and a comprehensive solution for consistent AKI classification in research applications for clinicians and data scientists working with AKI data. The pipeline\u2019s high accuracy make it a valuable tool for clinical research and decision support systems.   Conclusion This work introduces pyAKI as an open-source solution for implementing the KDIGO criteria for AKI diagnosis using time series data with high accuracy and performance.},\n    number = {1},\n}\n</code></pre>"},{"location":"getting_started/citing/#preprint","title":"Preprint","text":"<p>Our preprint is available on Arxiv.</p> <pre><code>@misc{porschen2024pyakiopensource,\n      title={pyAKI -- An Open Source Solution to Automated KDIGO classification},\n      author={Christian Porschen and Jan Ernsting and Paul Brauckmann and Raphael Weiss and Till W\u00fcrdemann and Hendrik Booke and Wida Amini and Ludwig Maidowski and Benjamin Risse and Tim Hahn and Thilo von Groote},\n      year={2024},\n      eprint={2401.12930},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG},\n      url={https://arxiv.org/abs/2401.12930},\n}\n</code></pre>"},{"location":"getting_started/contributing/","title":"Contributing","text":"<p>Here is how you can contribute to this project.</p>"},{"location":"getting_started/contributing/#setup","title":"Setup","text":"<p>Use the included dev container to automatically install all the necessary dev tools and dependencies.</p> <p>Prerequisite: To use this you first need to install docker under Linux, MacOS or WSL2 under windows.</p> <ol> <li> <p>Clone the repository: <pre><code>git clone git+https://github.com/aidh-ms/pyAKI\ncd pyAKI\n</code></pre></p> </li> <li> <p>Open the project in Visual Studio Code: <pre><code>code .\n</code></pre></p> </li> <li> <p>Reopen in Container:</p> <ul> <li>Press <code>F1</code> to open the command palette.</li> <li>Type <code>Remote-Containers: Reopen in Container</code> and select it.</li> <li>VS Code will build the Docker container defined in the <code>.devcontainer</code> folder and open the project inside the container.</li> </ul> </li> </ol>"},{"location":"getting_started/contributing/#development","title":"Development","text":""},{"location":"getting_started/contributing/#testing","title":"Testing","text":"<p>To test your contribution, you can use the testing tap in the VS code or utilise the following command to run the unit tests for this project:</p> <pre><code>poetry run pytest .\n</code></pre>"},{"location":"getting_started/installation/","title":"Installing pyAKI","text":""},{"location":"getting_started/installation/#requirements","title":"Requirements","text":"<p>The supported Python versions for this Python library are the following: * 3.12 * 3.13</p>"},{"location":"getting_started/installation/#installing-from-pypi","title":"Installing from PyPI","text":"<p>The pyAKI library can be installed from PyPI using various package managers.</p> <p>With pip <pre><code>pip install pyAKI\n</code></pre></p> <p>With poetry <pre><code>poetry add pyAKI\n</code></pre></p>"},{"location":"getting_started/installation/#installing-from-source","title":"Installing from Source","text":"<p>The pyAKI library can be installed from source (GitHub).</p> <p>With pip <pre><code>pip install git+https://github.com/aidh-ms/pyAKI\n</code></pre></p> <p>With poetry <pre><code>poetry add git+https://github.com/aidh-ms/pyAKI\n</code></pre></p>"},{"location":"getting_started/installation/#dependencies","title":"Dependencies","text":"<p>This library has the following dependencies:</p> <ul> <li>Pandas</li> <li>SciPy</li> <li>Typer</li> </ul>"},{"location":"getting_started/overview/","title":"Package overview","text":"<p>Python package to detect AKI within time series data.</p> <p>The goal of this package is to establish well tested, comprehensive functions for the detection of Acute Kidney Injury (AKI) in time series data, according to the Kidney Disease Improving Global Outcomes (KDIGO) Criteria, established in 2012 <sup>1</sup>. </p>"},{"location":"getting_started/overview/#license","title":"License","text":"<pre><code>MIT License\n\nCopyright (c) 2023 AIDH MS\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre> <ol> <li> <p>Improving Global Outcomes (KDIGO) Acute Kidney Injury Work Group. KDIGO Clinical Practice Guideline for Acute Kidney Injury. Kidney inter., Suppl. 2012; 2: 1\u2013138.\u00a0\u21a9</p> </li> </ol>"},{"location":"guide/preprocessing/","title":"Preprocessing Functions in pyAKI","text":""},{"location":"guide/preprocessing/#overview","title":"Overview","text":"<p>Before analyzing AKI (Acute Kidney Injury) data, it's essential to preprocess it correctly. <code>pyAKI</code> provides multiple preprocessing functions to handle time indexing, creatinine levels, urine output, demographics, and renal replacement therapy (RRT) status.</p>"},{"location":"guide/preprocessing/#importing-required-libraries","title":"Importing Required Libraries","text":"<pre><code>from pyaki.kdigo import Analyser\nfrom pyaki.preprocessors import (\n    CreatininePreProcessor,\n    DemographicsPreProcessor,\n    RRTPreProcessor,\n    TimeIndexCreator,\n    UrineOutputPreProcessor\n)\n</code></pre>"},{"location":"guide/preprocessing/#loading-data","title":"Loading data","text":"<p>The input data includes patient id, event time,  weight, urine output, creatinine level and if the patient has undergone RRT or not.</p> <pre><code>import pandas as pd\n\nvalidation_data = pd.read_csv(\"tests/data/validation_data.csv\")\n</code></pre>"},{"location":"guide/preprocessing/#time-index-creation","title":"Time Index Creation","text":"<p>The <code>TimeIndexCreator</code> ensures that data is properly indexed by time before analysis.</p> <pre><code>TimePrep = TimeIndexCreator(\n    stay_identifier=\"stay_id\",\n    time_identifier=\"charttime\"\n)\n</code></pre>"},{"location":"guide/preprocessing/#urine-output-preprocessing","title":"Urine Output Preprocessing","text":"<p>Handles missing or incorrect urine output values.</p> <pre><code>UrinPrep = UrineOutputPreProcessor(\n    stay_identifier=\"stay_id\",\n    time_identifier=\"charttime\",\n    interpolate=True,  # Flag indicating whether to interpolate missing values\n    threshold=6,  # The threshold value for limiting the interpolation range\n)\n</code></pre>"},{"location":"guide/preprocessing/#creatinine-preprocessing","title":"Creatinine Preprocessing","text":"<p>Ensures proper handling of creatinine values, including forward-filling missing data.</p> <pre><code>CreatPrep = CreatininePreProcessor(\n    stay_identifier=\"stay_id\",\n    time_identifier=\"charttime\",\n    ffill=True,  # Forward-fill missing values\n    threshold=72  # The threshold value for limiting the forward filling range\n)\n</code></pre>"},{"location":"guide/preprocessing/#demographics-preprocessing","title":"Demographics Preprocessing","text":"<p>Processes patient demographic data (age, weight, gender, etc.).</p> <pre><code>DemoPrep = DemographicsPreProcessor(\n    stay_identifier=\"stay_id\",\n    time_identifier=\"charttime\"\n)\n</code></pre>"},{"location":"guide/preprocessing/#renal-replacement-therapy-rrt-preprocessing","title":"Renal Replacement Therapy (RRT) Preprocessing","text":"<p>Processes RRT status changes.</p> <pre><code>RRTPrep = RRTPreProcessor(\n    stay_identifier=\"stay_id\",\n    time_identifier=\"charttime\"\n)\n</code></pre>"},{"location":"guide/preprocessing/#running-preprocessing-before-analysis","title":"Running Preprocessing Before Analysis","text":"<p>Before running an analysis, apply the preprocessing steps:</p> <pre><code>data = [\n    Dataset(DatasetType.URINEOUTPUT, validation_data),\n    Dataset(DatasetType.CREATININE, validation_data),\n    Dataset(DatasetType.DEMOGRAPHICS, validation_data),\n    Dataset(DatasetType.RRT, validation_data),\n]\n\nanalyser = Analyser(\n    data,\n    preprocessors=[TimePrep, UrinPrep, CreatPrep, DemoPrep, RRTPrep]\n)\n\nresults = analyser.process_stays()\n</code></pre> <p>In case of not specifying Preprocessing, the Analyser will run all five Preprocessings with its default setting.</p>"},{"location":"guide/preprocessing/#extracting-results-for-a-single-patient","title":"Extracting Results for a Single Patient","text":"<pre><code>results_one_id = analyser.process_stay(stay_id=32314488)\nprint(results_one_id[:1])\n</code></pre>"},{"location":"guide/probes/","title":"Using Probes in pyAKI","text":""},{"location":"guide/probes/#overview","title":"Overview","text":"<p>Probes in <code>pyAKI</code> allow for detecting Acute Kidney Injury (AKI) based on different clinical markers such as absolute or relative creatinine levels, urine output, and renal replacement therapy (RRT). The <code>AbsoluteCreatinineProbe</code>, <code>RelativeCreatinineProbe</code>, <code>UrineOutputProbe</code> and <code>RRTProbe</code> provide various methods to define AKI stages. In general, it adds one resulted column for each specified probe and a general evaluation column of the AKI stage.</p> <p></p>"},{"location":"guide/probes/#importing-required-libraries","title":"Importing Required Libraries","text":"<pre><code>from pyaki.kdigo import Analyser\nfrom pyaki.probes import (\n    AbsoluteCreatinineProbe, CreatinineBaselineMethod, Dataset, DatasetType,\n    RelativeCreatinineProbe, RRTProbe, UrineOutputMethod, UrineOutputProbe\n)\n</code></pre>"},{"location":"guide/probes/#loading-data","title":"Loading Data","text":"<p>The input data included patient id, event time,  weight, urine output, creatinine level and if the patient has undergone RRT or not.</p> <pre><code>import pandas as pd\n\nvalidation_data = pd.read_csv(\"tests/data/validation_data.csv\")\n</code></pre>"},{"location":"guide/probes/#using-absolute-creatinine-probe","title":"Using Absolute Creatinine Probe","text":"<p>The <code>AbsoluteCreatinineProbe</code> determines AKI stages using the provided data frame and a predefined baseline calculation method (see table below for a comprehensive list of methods).</p> <pre><code>AbsCreatProbe = AbsoluteCreatinineProbe(\n    column=\"creat\",\n    method=CreatinineBaselineMethod.ROLLING_MIN,  # Choose any method from below\n    baseline_timeframe = \"1d\" # Default value: \"2d\"\n)\n</code></pre>"},{"location":"guide/probes/#list-of-creatinine-baseline-calculation-methods","title":"List of Creatinine Baseline Calculation Methods","text":"Method Description Usage Example ROLLING_MIN Uses the minimum creatinine value within a rolling window (default: 72) following the observation time as the baseline. Suitable when analyzing short-term trends in creatinine fluctuations. ROLLING_FIRST Uses the first value in a rolling window following the observation time as the baseline. Use when the earliest observed creatinine level is expected to be the most accurate reference. ROLLING_MEAN Uses the mean creatinine value within a rolling window. Ideal for smoothing fluctuations in creatinine values over time. FIXED_MIN Uses the minimum creatinine value from the first n days of observation (default: n = 72). Best when a low baseline value from an early stage is needed. FIXED_MEAN Uses the mean creatinine value from the first n days of observation. Useful for creating a stable baseline based on initial observations. OVERALL_FIRST Uses the first recorded creatinine value as the baseline. Use when assuming the first available measurement represents the patient\u2019s true baseline. OVERALL_MEAN Uses the mean of all observed creatinine values as the baseline. Best when considering long-term average creatinine levels. OVERALL_MIN Uses the minimum of all observed creatinine values as the baseline. Use when assuming the lowest creatinine level reflects normal kidney function. CONSTANT Uses a predefined constant value as the baseline. Useful for benchmark comparisons or when no historical data is available. CALCULATED Uses a calculated value based on the Cockcroft-Gault Formula and Adjusted Body Weight. Best for cases where patient demographics (age, weight, gender) influence baseline creatinine levels. <p>The Cockcroft-Gault Formula is:</p> \\[ \\text{Creatinine Clearance, mg/dl} = \\frac{(140 - \\text{age}) \\times \\text{ABW} (\\times 0.85 \\text{ if female})}{70 \\times \\text{Expected Clearance}} \\] <p>where the ABW (Adjusted Body Weight) Calculation is:</p> \\[ \\text{ABW} = \\text{IBW} + 0.4 \\times (\\text{weight} - \\text{IBW}). \\]"},{"location":"guide/probes/#example-of-constant-baseline-method","title":"Example of constant baseline method","text":"<pre><code>validation_data_unlabelled['baseline_column'] = validation_data_unlabelled.loc[:, 'creat'].mean()\n\nAbsCreatProbe = AbsoluteCreatinineProbe(column=\"creat\",\n                                baseline_constant_column = \"baseline_column\",\n                                method=CreatinineBaselineMethod.CONSTANT)\n</code></pre>"},{"location":"guide/probes/#example-of-calculated-baseline-method","title":"Example of calculated baseline method","text":"<p>See below.</p>"},{"location":"guide/probes/#using-relative-creatinine-probe","title":"Using Relative Creatinine Probe","text":"<p>The <code>RelativeCreatinineProbe</code> determines AKI stages by comparing changes in creatinine levels relative to baseline values. The list and use of available baseline methods is similar to of Absolute Creatinine Probe. The users are encouraged to look into Absolute Creatinine Probe section.</p> <pre><code>RelCreatProb = RelativeCreatinineProbe(\n    column=\"creat\",\n    method=CreatinineBaselineMethod.ROLLING_MEAN,\n    baseline_timeframe = \"7d\" #Default value: \"7d\"\n)\n</code></pre>"},{"location":"guide/probes/#using-urine-output-probe","title":"Using Urine Output Probe","text":"<p>The <code>UrineOutputProbe</code> assesses AKI based on urine output levels, considering patient weight and anuria thresholds.</p> <pre><code>UrineProbe = UrineOutputProbe(\n    column=\"urineoutput\",\n    patient_weight_column=\"patient_weight\",\n    anuria_limit=0.2, #Default value: 0.1\n    method=UrineOutputMethod.STRICT #Choose a suitable method from below\n)\n</code></pre> <p>The list of calculation methods includes:</p>"},{"location":"guide/probes/#urine-output-calculation-methods","title":"Urine Output Calculation Methods","text":"Method Description Usage Example STRICT Strict method for urine output calculations. The urine output stage is calculated based on the maximum urine output in the past 6, 12, and 24 hours. Use this method for precise tracking of urine output in a specific window of time. MEAN Mean method for urine output calculations. The urine output stage is calculated using the average urine output over a certain period. Suitable for calculating overall trends in urine output over time."},{"location":"guide/probes/#using-rrt-probe","title":"Using RRT Probe","text":"<p>The Renal Replacement Therapy <code>RRT</code> Probe classifies a patient with a KDIGO stage 3 if the patient is on RRT at any time during the ICU stay. It will return 0 otherwise.</p> <pre><code>RRTProbe = RRTProbe(column=\"rrt\")\n</code></pre>"},{"location":"guide/probes/#running-analysis-with-probes","title":"Running Analysis with Probes","text":"<pre><code>data = [\n    Dataset(DatasetType.URINEOUTPUT, validation_data_),\n    Dataset(DatasetType.CREATININE, validation_data),\n    Dataset(DatasetType.DEMOGRAPHICS, validation_data),\n    Dataset(DatasetType.RRT, validation_data),\n]\n\nanalyser = Analyser(\n    data,\n    probes=[UrineProbe, AbsCreatProbe, RelCreatProb] # Specify which probes used\n)\n\nresults = analyser.process_stays()\n</code></pre>"},{"location":"guide/probes/#special-case-of-calculated-baseline-method","title":"Special case of calculated baseline method","text":"<p>The usage of calculaed baseline method is different from others that we need to supply a new dataframe with information of age, height, weight and gender of each patient into data.</p> <pre><code>random.seed(1)\nn = len(validation_data)\nage = random.choices(list(range(10,90)), k=n)\nheight = random.choices(list(range(140,180)), k=n)\ngender = random.choices([\"M\", \"F\"], k=n)\nadded_validation_data[\"age\"]= age\nadded_validation_data[\"height\"] = height\nadded_validation_data[\"gender\"] = gender\n\n\nAbsCreatProbe = AbsoluteCreatinineProbe(column=\"creat\", patient_age_column=\"age\",\n                                        patient_gender_column=\"gender\",\n                                        patient_height_column=\"height\",\n                                        patient_weight_column=\"patient_weight\",\n                                        expected_clearance = 72, #Default value: 72\n                                        method=CreatinineBaselineMethod.CALCULATED)\n\ndata = [\n    Dataset(DatasetType.URINEOUTPUT, validation_data),\n    Dataset(DatasetType.CREATININE, validation_data),\n    Dataset(DatasetType.DEMOGRAPHICS, added_validation_data),\n    Dataset(DatasetType.RRT, validation_data_unlabelled),\n]\n\nanalyser = Analyser(\n    data,\n    probes=[AbsCreatProbe]\n)\n\nresults = analyser.process_stays()\n</code></pre>"},{"location":"guide/probes/#extracting-results-for-a-single-patient","title":"Extracting Results for a Single Patient","text":"<pre><code>results_one_id = analyser.process_stay(stay_id=32314488)\nprint(results_one_id.tail(1))\n</code></pre>"},{"location":"guide/tutorial/","title":"Introduction to pyAKI","text":"<p>Welcome to the pyAKI tutorial! This guide will help you understand how to use the pyAKI Python package for Acute Kidney Injury (AKI) detection based on creatinine levels, urine output, and renal replacement therapy (RRT) data.</p> <p>This tutorial is divided into two sections:</p> <ol> <li>Using Probes - Learn how to apply different probe methods to analyze AKI.</li> <li>Preprocessing Functions - Learn about data preparation techniques before analysis.</li> </ol>"},{"location":"guide/tutorial/#installation","title":"Installation","text":"<p>See Installation.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>pyaki<ul> <li>bin<ul> <li>process_aki_stages</li> </ul> </li> <li>kdigo</li> <li>preprocessors</li> <li>probes</li> <li>utils</li> </ul> </li> </ul>"},{"location":"reference/pyaki/","title":"pyaki","text":"<p>pyaki: A Python package for classification of acute kidney injury.</p> <p>This package provides a Python API and CLI tool for analysing time series to classification of acute kidney injury.</p> <p>Modules: - bin: Command line interface for the pyaki package. - kdigo: Implementation of the KDIGO criteria for classification of acute kidney injury. - preprocessing: Preprocessing of time series data. - probes: Implementation of the probes for classification of acute kidney injury. - utils: Utility functions for the pyaki package.</p> <p>Usage: <pre><code>import pandas as pd\n\nfrom pyaki.kdigo import Analyser\nfrom pyaki.probes import Dataset, DatasetType\n\ndatasets: list[Dataset] =[\n    Dataset(DatasetType.URINEOUTPUT, pd.DataFrame()),\n    Dataset(DatasetType.CREATININE, pd.DataFrame()),\n    Dataset(DatasetType.DEMOGRAPHICS, pd.DataFrame()),\n    Dataset(DatasetType.RRT, pd.DataFrame()),\n]\n\nanalyser = Analyser(datasets)\nreult_df = analyser.process_stays()\n</code></pre></p> <p>Author: - Christian Porschen - Jan Ernsting - Paul Brauckmann</p> <p>License: <pre><code>MIT License\n\nCopyright (c) 2023 AIDH MS\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre></p>"},{"location":"reference/pyaki/kdigo/","title":"kdigo","text":"<p>This module contains the analysis class for processing AKI stages from time series data.</p>"},{"location":"reference/pyaki/kdigo/#pyaki.kdigo.Analyser","title":"<code>Analyser</code>","text":"<p>Class for data analysis using probes and preprocessors.</p> <p>This class provides functionality for analyzing data using a collection of probes and preprocessors. It processes the input data through the specified preprocessors and applies the probes to perform the analysis. The analysis results are returned as a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list[Dataset]</code> <p>A list of Dataset objects containing the input data.</p> required <code>probes</code> <code>list[Probe]</code> <p>A list of Probe objects representing the analysis probes to apply. If not provided, default probes including UrineOutputProbe, AbsoluteCreatinineProbe, and RelativeCreatinineProbe will be used.</p> <code>None</code> <code>preprocessors</code> <code>list[Preprocessor]</code> <p>A list of Preprocessor objects representing the preprocessors to apply on the input data. If not provided, default preprocessors including UrineOutputPreProcessor, CreatininePreProcessor, and DemographicsPreProcessor will be used.</p> <code>None</code> <code>stay_identifier</code> <code>str</code> <p>The column name in the input data representing the stay identifier.</p> <code>\"stay_id\"</code> <code>time_identifier</code> <code>str</code> <p>The column name in the input data representing the time identifier.</p> <code>\"charttime\"</code> <p>Examples:</p> <p>Instantiate the Analyser class with custom data, probes, and preprocessors <pre><code>&gt;&gt;&gt; analyser = Analyser(data=my_datasets, probes=[MyProbe()], preprocessors=[MyPreprocessor()])\n</code></pre></p> <p>Process stays and obtain the analysis results <pre><code>&gt;&gt;&gt; result_df = analyser.process_stays()\n</code></pre></p> Source code in <code>pyaki/kdigo.py</code> <pre><code>class Analyser:\n    \"\"\"\n    Class for data analysis using probes and preprocessors.\n\n    This class provides functionality for analyzing data using a collection of probes and preprocessors.\n    It processes the input data through the specified preprocessors and applies the probes to perform\n    the analysis. The analysis results are returned as a DataFrame.\n\n    Parameters\n    ----------\n    data : list[Dataset]\n        A list of Dataset objects containing the input data.\n    probes : list[Probe], optional\n        A list of Probe objects representing the analysis probes to apply. If not provided, default\n        probes including UrineOutputProbe, AbsoluteCreatinineProbe, and RelativeCreatinineProbe will be used.\n    preprocessors : list[Preprocessor], optional\n        A list of Preprocessor objects representing the preprocessors to apply on the input data. If not\n        provided, default preprocessors including UrineOutputPreProcessor, CreatininePreProcessor, and\n        DemographicsPreProcessor will be used.\n    stay_identifier : str, default: \"stay_id\"\n        The column name in the input data representing the stay identifier.\n    time_identifier : str, default: \"charttime\"\n        The column name in the input data representing the time identifier.\n\n    Examples\n    --------\n    Instantiate the Analyser class with custom data, probes, and preprocessors\n    ```pycon\n    &gt;&gt;&gt; analyser = Analyser(data=my_datasets, probes=[MyProbe()], preprocessors=[MyPreprocessor()])\n    ```\n\n    Process stays and obtain the analysis results\n    ```pycon\n    &gt;&gt;&gt; result_df = analyser.process_stays()\n    ```\n    \"\"\"\n\n    def __init__(\n        self,\n        data: list[Dataset],\n        probes: Optional[list[Probe]] = None,\n        preprocessors: Optional[list[Preprocessor]] = None,\n        stay_identifier: str = \"stay_id\",\n        time_identifier: str = \"charttime\",\n    ) -&gt; None:\n        if probes is None:  # apply default probes if not provided\n            probes = [\n                UrineOutputProbe(),\n                AbsoluteCreatinineProbe(),\n                RelativeCreatinineProbe(),\n                RRTProbe(),\n            ]\n        if preprocessors is None:  # apply default preprocessors if not provided\n            preprocessors = [\n                TimeIndexCreator(stay_identifier=stay_identifier, time_identifier=time_identifier),\n                UrineOutputPreProcessor(stay_identifier=stay_identifier, time_identifier=time_identifier),\n                CreatininePreProcessor(stay_identifier=stay_identifier, time_identifier=time_identifier),\n                DemographicsPreProcessor(stay_identifier=stay_identifier),\n                RRTPreProcessor(stay_identifier=stay_identifier, time_identifier=time_identifier),\n            ]\n\n        # validate datasets\n        self.validate_data(data)\n\n        # apply preprocessors to the input data\n        logger.info(\"Start preprocessing\")\n        for preprocessor in preprocessors:\n            data = preprocessor.process(data)\n\n        logger.info(\"Finish preprocessing\")\n\n        self._data: list[Dataset] = data\n        self._probes: list[Probe] = probes\n        self._stay_identifier: str = stay_identifier\n\n    def validate_data(self, datasets: list[Dataset]) -&gt; None:\n        \"\"\"\n        validate the input data for negative values.\n\n        Parameters\n        ----------\n        datasets : list[Dataset]\n            A list of Dataset objects containing the input data.\n\n        Raises\n        ------\n        ValueError\n            If any of the datasets contain negative values.\n        \"\"\"\n        for dtype, df in datasets:\n            try:\n                if (df &lt; 0).values.any():\n                    raise ValueError(f\"Dataset of Type {dtype} contains negative data\")\n            except TypeError:\n                continue\n\n    def process_stays(self) -&gt; pd.DataFrame:\n        \"\"\"\n        Process all stays in the input data.\n\n        This method processes all stays in the input data by applying the configured probes.\n        The analysis results for all stays are concatenated and returned as a single DataFrame.\n\n        Returns\n        -------\n        pd.DataFrame\n            The analysis results for all stays.\n        \"\"\"\n        logger.info(\"Start probing\")\n\n        (_, df), *datasets = self._data\n        stay_ids: pd.Index = df.index.get_level_values(self._stay_identifier).unique()\n        for _, df in datasets:\n            stay_ids.join(df.index.get_level_values(self._stay_identifier).unique())\n\n        data: pd.DataFrame = self.process_stay(stay_ids.values[0])\n        for stay_id in stay_ids.values[1:]:\n            data = pd.concat([data, self.process_stay(stay_id)])\n\n        logger.info(\"Finish probing\")\n        return data\n\n    def process_stay(self, stay_id: str) -&gt; pd.DataFrame:\n        \"\"\"\n        Process a specific stay in the input data by patient identificator.\n\n        This method processes a specific stay in the input data by applying the configured probes and preprocessors.\n        The analysis results for the stay are returned as a DataFrame.\n\n        Parameters\n        ----------\n        stay_id : str\n            The identifier of the stay to process.\n\n        Returns\n        -------\n        pd.DataFrame\n            The analysis results for the specific stay.\n        \"\"\"\n        logger.debug(\"Processing stay with id: %s\", stay_id)\n\n        datasets: list[Dataset] = [\n            Dataset(dtype, data.loc[stay_id])  # type: ignore\n            for dtype, data in self._data\n            if stay_id in data.index\n        ]\n\n        for probe in self._probes:\n            datasets = probe.probe(datasets)\n\n        (_, df), *datasets = datasets\n        for _, _df in datasets:\n            if isinstance(_df, pd.Series):\n                _df = pd.DataFrame([_df], index=df.index)\n            columns = set(_df.columns) - set(df.columns)\n            df = df.merge(_df[[*columns]], how=\"outer\", left_index=True, right_index=True)\n\n        df[\"stage\"] = df.filter(like=\"stage\").max(axis=1)\n        return df.set_index(\n            pd.MultiIndex.from_arrays(\n                [[stay_id] * len(df), df.index.values],\n                names=(self._stay_identifier, df.index.name),\n            )\n        )\n</code></pre>"},{"location":"reference/pyaki/kdigo/#pyaki.kdigo.Analyser.process_stay","title":"<code>process_stay(stay_id)</code>","text":"<p>Process a specific stay in the input data by patient identificator.</p> <p>This method processes a specific stay in the input data by applying the configured probes and preprocessors. The analysis results for the stay are returned as a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>stay_id</code> <code>str</code> <p>The identifier of the stay to process.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The analysis results for the specific stay.</p> Source code in <code>pyaki/kdigo.py</code> <pre><code>def process_stay(self, stay_id: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Process a specific stay in the input data by patient identificator.\n\n    This method processes a specific stay in the input data by applying the configured probes and preprocessors.\n    The analysis results for the stay are returned as a DataFrame.\n\n    Parameters\n    ----------\n    stay_id : str\n        The identifier of the stay to process.\n\n    Returns\n    -------\n    pd.DataFrame\n        The analysis results for the specific stay.\n    \"\"\"\n    logger.debug(\"Processing stay with id: %s\", stay_id)\n\n    datasets: list[Dataset] = [\n        Dataset(dtype, data.loc[stay_id])  # type: ignore\n        for dtype, data in self._data\n        if stay_id in data.index\n    ]\n\n    for probe in self._probes:\n        datasets = probe.probe(datasets)\n\n    (_, df), *datasets = datasets\n    for _, _df in datasets:\n        if isinstance(_df, pd.Series):\n            _df = pd.DataFrame([_df], index=df.index)\n        columns = set(_df.columns) - set(df.columns)\n        df = df.merge(_df[[*columns]], how=\"outer\", left_index=True, right_index=True)\n\n    df[\"stage\"] = df.filter(like=\"stage\").max(axis=1)\n    return df.set_index(\n        pd.MultiIndex.from_arrays(\n            [[stay_id] * len(df), df.index.values],\n            names=(self._stay_identifier, df.index.name),\n        )\n    )\n</code></pre>"},{"location":"reference/pyaki/kdigo/#pyaki.kdigo.Analyser.process_stays","title":"<code>process_stays()</code>","text":"<p>Process all stays in the input data.</p> <p>This method processes all stays in the input data by applying the configured probes. The analysis results for all stays are concatenated and returned as a single DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The analysis results for all stays.</p> Source code in <code>pyaki/kdigo.py</code> <pre><code>def process_stays(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Process all stays in the input data.\n\n    This method processes all stays in the input data by applying the configured probes.\n    The analysis results for all stays are concatenated and returned as a single DataFrame.\n\n    Returns\n    -------\n    pd.DataFrame\n        The analysis results for all stays.\n    \"\"\"\n    logger.info(\"Start probing\")\n\n    (_, df), *datasets = self._data\n    stay_ids: pd.Index = df.index.get_level_values(self._stay_identifier).unique()\n    for _, df in datasets:\n        stay_ids.join(df.index.get_level_values(self._stay_identifier).unique())\n\n    data: pd.DataFrame = self.process_stay(stay_ids.values[0])\n    for stay_id in stay_ids.values[1:]:\n        data = pd.concat([data, self.process_stay(stay_id)])\n\n    logger.info(\"Finish probing\")\n    return data\n</code></pre>"},{"location":"reference/pyaki/kdigo/#pyaki.kdigo.Analyser.validate_data","title":"<code>validate_data(datasets)</code>","text":"<p>validate the input data for negative values.</p> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>list[Dataset]</code> <p>A list of Dataset objects containing the input data.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If any of the datasets contain negative values.</p> Source code in <code>pyaki/kdigo.py</code> <pre><code>def validate_data(self, datasets: list[Dataset]) -&gt; None:\n    \"\"\"\n    validate the input data for negative values.\n\n    Parameters\n    ----------\n    datasets : list[Dataset]\n        A list of Dataset objects containing the input data.\n\n    Raises\n    ------\n    ValueError\n        If any of the datasets contain negative values.\n    \"\"\"\n    for dtype, df in datasets:\n        try:\n            if (df &lt; 0).values.any():\n                raise ValueError(f\"Dataset of Type {dtype} contains negative data\")\n        except TypeError:\n            continue\n</code></pre>"},{"location":"reference/pyaki/preprocessors/","title":"preprocessors","text":"<p>This module contains the preprocessors used in the pyaki package.</p>"},{"location":"reference/pyaki/preprocessors/#pyaki.preprocessors.CreatininePreProcessor","title":"<code>CreatininePreProcessor</code>","text":"<p>               Bases: <code>Preprocessor</code></p> <p>Preprocessor for processing the creatinine dataset.</p> <p>Parameters:</p> Name Type Description Default <code>stay_identifier</code> <code>str</code> <p>The column name that identifies stays or admissions in the dataset.</p> <code>\"stay_id\"</code> <code>time_identifier</code> <code>str</code> <p>The column name that identifies the timestamp or time variable in the dataset.</p> <code>\"charttime\"</code> <code>creatinine_column</code> <code>str</code> <p>The column name that represents the creatinine values in the dataset.</p> <code>\"creat\"</code> <code>ffill</code> <code>bool</code> <p>Flag indicating whether to perform forward filling on missing values.</p> <code>True</code> <code>threshold</code> <code>int</code> <p>The threshold value for limiting the forward filling range.</p> <code>72</code> Source code in <code>pyaki/preprocessors.py</code> <pre><code>class CreatininePreProcessor(Preprocessor):\n    \"\"\"\n    Preprocessor for processing the creatinine dataset.\n\n    Parameters\n    ----------\n    stay_identifier : str, default: \"stay_id\"\n        The column name that identifies stays or admissions in the dataset.\n    time_identifier : str, default: \"charttime\"\n        The column name that identifies the timestamp or time variable in the dataset.\n    creatinine_column : str, default: \"creat\"\n        The column name that represents the creatinine values in the dataset.\n    ffill : bool, default: True\n        Flag indicating whether to perform forward filling on missing values.\n    threshold : int, default: 72\n        The threshold value for limiting the forward filling range.\n    \"\"\"\n\n    def __init__(\n        self,\n        stay_identifier: str = \"stay_id\",\n        time_identifier: str = \"charttime\",\n        creatinine_column: str = \"creat\",\n        ffill: bool = True,\n        threshold: int = 72,\n    ) -&gt; None:\n        super().__init__(stay_identifier, time_identifier)\n\n        self._ffill: bool = ffill\n        self._threshold: Optional[int] = threshold\n        self._creatinine_column: str = creatinine_column\n\n    @dataset_as_df(df=DatasetType.CREATININE)\n    @df_to_dataset(DatasetType.CREATININE)\n    def process(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Process the creatinine dataset by resampling and performing forward filling on missing values.\n\n        Parameters\n        ----------\n        df : pd.DataFrame\n            The input creatinine dataset as a pandas DataFrame.\n\n        Returns\n        -------\n        pd.DataFrame\n            The processed creatinine dataset as a pandas DataFrame.\n        \"\"\"\n        df = df.groupby(self._stay_identifier).resample(\"1h\").mean()  # type: ignore\n        if not self._ffill:\n            return df\n\n        df[df[self._creatinine_column] == 0] = None\n        return df.ffill(limit=self._threshold)\n</code></pre>"},{"location":"reference/pyaki/preprocessors/#pyaki.preprocessors.CreatininePreProcessor.process","title":"<code>process(df)</code>","text":"<p>Process the creatinine dataset by resampling and performing forward filling on missing values.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input creatinine dataset as a pandas DataFrame.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The processed creatinine dataset as a pandas DataFrame.</p> Source code in <code>pyaki/preprocessors.py</code> <pre><code>@dataset_as_df(df=DatasetType.CREATININE)\n@df_to_dataset(DatasetType.CREATININE)\ndef process(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Process the creatinine dataset by resampling and performing forward filling on missing values.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The input creatinine dataset as a pandas DataFrame.\n\n    Returns\n    -------\n    pd.DataFrame\n        The processed creatinine dataset as a pandas DataFrame.\n    \"\"\"\n    df = df.groupby(self._stay_identifier).resample(\"1h\").mean()  # type: ignore\n    if not self._ffill:\n        return df\n\n    df[df[self._creatinine_column] == 0] = None\n    return df.ffill(limit=self._threshold)\n</code></pre>"},{"location":"reference/pyaki/preprocessors/#pyaki.preprocessors.DemographicsPreProcessor","title":"<code>DemographicsPreProcessor</code>","text":"<p>               Bases: <code>Preprocessor</code></p> <p>Preprocessor for processing the demographics dataset.</p> Source code in <code>pyaki/preprocessors.py</code> <pre><code>class DemographicsPreProcessor(Preprocessor):\n    \"\"\"Preprocessor for processing the demographics dataset.\"\"\"\n\n    @dataset_as_df(df=DatasetType.DEMOGRAPHICS)\n    @df_to_dataset(DatasetType.DEMOGRAPHICS)\n    def process(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Process the demographics dataset by aggregating the data based on stay identifiers.\n\n        Parameters\n        ----------\n        df : pd.DataFrame\n            The input demographics dataset as a pandas DataFrame.\n\n        Returns\n        -------\n        pd.DataFrame\n            The processed demographics dataset as a pandas DataFrame.\n        \"\"\"\n        return df.groupby(self._stay_identifier).last()\n</code></pre>"},{"location":"reference/pyaki/preprocessors/#pyaki.preprocessors.DemographicsPreProcessor.process","title":"<code>process(df)</code>","text":"<p>Process the demographics dataset by aggregating the data based on stay identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input demographics dataset as a pandas DataFrame.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The processed demographics dataset as a pandas DataFrame.</p> Source code in <code>pyaki/preprocessors.py</code> <pre><code>@dataset_as_df(df=DatasetType.DEMOGRAPHICS)\n@df_to_dataset(DatasetType.DEMOGRAPHICS)\ndef process(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Process the demographics dataset by aggregating the data based on stay identifiers.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The input demographics dataset as a pandas DataFrame.\n\n    Returns\n    -------\n    pd.DataFrame\n        The processed demographics dataset as a pandas DataFrame.\n    \"\"\"\n    return df.groupby(self._stay_identifier).last()\n</code></pre>"},{"location":"reference/pyaki/preprocessors/#pyaki.preprocessors.Preprocessor","title":"<code>Preprocessor</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for preprocessors.</p> <p>Parameters:</p> Name Type Description Default <code>stay_identifier</code> <code>str</code> <p>The column name that identifies stays or admissions in the dataset.</p> <code>\"stay_id\"</code> <code>time_identifier</code> <code>str</code> <p>The column name that identifies the timestamp or time variable in the dataset.</p> <code>\"charttime\"</code> Source code in <code>pyaki/preprocessors.py</code> <pre><code>class Preprocessor(ABC):\n    \"\"\"\n    Abstract base class for preprocessors.\n\n    Parameters\n    ----------\n    stay_identifier : str, default: \"stay_id\"\n        The column name that identifies stays or admissions in the dataset.\n    time_identifier : str, default: \"charttime\"\n        The column name that identifies the timestamp or time variable in the dataset.\n    \"\"\"\n\n    def __init__(self, stay_identifier: str = \"stay_id\", time_identifier: str = \"charttime\") -&gt; None:\n        super().__init__()\n\n        self._stay_identifier: str = stay_identifier\n        self._time_identifier: str = time_identifier\n\n    def process(self, datasets: list[Dataset]) -&gt; list[Dataset]:\n        \"\"\"\n        Process the given list of datasets and return the processed datasets.\n\n        Parameters\n        ----------\n        datasets : list[Dataset]\n            The list of datasets to be processed.\n\n        Returns\n        -------\n        list[Dataset]\n            The processed datasets.\n        \"\"\"\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/pyaki/preprocessors/#pyaki.preprocessors.Preprocessor.process","title":"<code>process(datasets)</code>","text":"<p>Process the given list of datasets and return the processed datasets.</p> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>list[Dataset]</code> <p>The list of datasets to be processed.</p> required <p>Returns:</p> Type Description <code>list[Dataset]</code> <p>The processed datasets.</p> Source code in <code>pyaki/preprocessors.py</code> <pre><code>def process(self, datasets: list[Dataset]) -&gt; list[Dataset]:\n    \"\"\"\n    Process the given list of datasets and return the processed datasets.\n\n    Parameters\n    ----------\n    datasets : list[Dataset]\n        The list of datasets to be processed.\n\n    Returns\n    -------\n    list[Dataset]\n        The processed datasets.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/pyaki/preprocessors/#pyaki.preprocessors.RRTPreProcessor","title":"<code>RRTPreProcessor</code>","text":"<p>               Bases: <code>Preprocessor</code></p> <p>Preprocessor for processing the RRT dataset.</p> Source code in <code>pyaki/preprocessors.py</code> <pre><code>class RRTPreProcessor(Preprocessor):\n    \"\"\"Preprocessor for processing the RRT dataset.\"\"\"\n\n    @dataset_as_df(df=DatasetType.RRT)\n    @df_to_dataset(DatasetType.RRT)\n    def process(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Process the RRT dataset by upsampling the data and forward filling the last value. We expect the dataframe to contain a 1 for RRT in progress, and 0 for RRT not in progress.\n\n        Parameters\n        ----------\n        df : pd.DataFrame\n            The input RRT dataset as a pandas DataFrame.\n\n        Returns\n        -------\n        pd.DataFrame\n            The processed RRT dataset as a pandas DataFrame.\n        \"\"\"\n        df = df.groupby(self._stay_identifier).resample(\"1h\").last()  # type: ignore\n        return df.ffill()\n</code></pre>"},{"location":"reference/pyaki/preprocessors/#pyaki.preprocessors.RRTPreProcessor.process","title":"<code>process(df)</code>","text":"<p>Process the RRT dataset by upsampling the data and forward filling the last value. We expect the dataframe to contain a 1 for RRT in progress, and 0 for RRT not in progress.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input RRT dataset as a pandas DataFrame.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The processed RRT dataset as a pandas DataFrame.</p> Source code in <code>pyaki/preprocessors.py</code> <pre><code>@dataset_as_df(df=DatasetType.RRT)\n@df_to_dataset(DatasetType.RRT)\ndef process(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Process the RRT dataset by upsampling the data and forward filling the last value. We expect the dataframe to contain a 1 for RRT in progress, and 0 for RRT not in progress.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The input RRT dataset as a pandas DataFrame.\n\n    Returns\n    -------\n    pd.DataFrame\n        The processed RRT dataset as a pandas DataFrame.\n    \"\"\"\n    df = df.groupby(self._stay_identifier).resample(\"1h\").last()  # type: ignore\n    return df.ffill()\n</code></pre>"},{"location":"reference/pyaki/preprocessors/#pyaki.preprocessors.TimeIndexCreator","title":"<code>TimeIndexCreator</code>","text":"<p>               Bases: <code>Preprocessor</code></p> <p>Preprocessor for creating a time index in the datasets.</p> <p>Attributes:</p> Name Type Description <code>DATASETS</code> <code>list[DatasetType]</code> <p>The list of dataset types that require a time index.</p> Source code in <code>pyaki/preprocessors.py</code> <pre><code>class TimeIndexCreator(Preprocessor):\n    \"\"\"\n    Preprocessor for creating a time index in the datasets.\n\n    Attributes\n    ----------\n    DATASETS : list[DatasetType]\n        The list of dataset types that require a time index.\n    \"\"\"\n\n    DATASETS: list[DatasetType] = [\n        DatasetType.CREATININE,\n        DatasetType.URINEOUTPUT,\n        DatasetType.RRT,\n    ]\n\n    def process(self, datasets: list[Dataset]) -&gt; list[Dataset]:\n        \"\"\"\n        Process the datasets by creating a time index if the dataset type requires it.\n\n        Parameters\n        ----------\n        datasets : list[Dataset]\n            The list of datasets to be processed.\n\n        Returns\n        -------\n        list[Dataset]\n            The processed datasets.\n        \"\"\"\n        _datasets = []\n        for dtype, df in datasets:\n            if dtype not in self.DATASETS or self._time_identifier not in df.columns:\n                _datasets.append(Dataset(dtype, df))\n                continue\n\n            if not is_datetime64_any_dtype(df[self._time_identifier]):\n                df[self._time_identifier] = pd.to_datetime(df[self._time_identifier])\n\n            _datasets.append(Dataset(dtype, df.set_index(self._time_identifier)))\n\n        return _datasets\n</code></pre>"},{"location":"reference/pyaki/preprocessors/#pyaki.preprocessors.TimeIndexCreator.process","title":"<code>process(datasets)</code>","text":"<p>Process the datasets by creating a time index if the dataset type requires it.</p> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>list[Dataset]</code> <p>The list of datasets to be processed.</p> required <p>Returns:</p> Type Description <code>list[Dataset]</code> <p>The processed datasets.</p> Source code in <code>pyaki/preprocessors.py</code> <pre><code>def process(self, datasets: list[Dataset]) -&gt; list[Dataset]:\n    \"\"\"\n    Process the datasets by creating a time index if the dataset type requires it.\n\n    Parameters\n    ----------\n    datasets : list[Dataset]\n        The list of datasets to be processed.\n\n    Returns\n    -------\n    list[Dataset]\n        The processed datasets.\n    \"\"\"\n    _datasets = []\n    for dtype, df in datasets:\n        if dtype not in self.DATASETS or self._time_identifier not in df.columns:\n            _datasets.append(Dataset(dtype, df))\n            continue\n\n        if not is_datetime64_any_dtype(df[self._time_identifier]):\n            df[self._time_identifier] = pd.to_datetime(df[self._time_identifier])\n\n        _datasets.append(Dataset(dtype, df.set_index(self._time_identifier)))\n\n    return _datasets\n</code></pre>"},{"location":"reference/pyaki/preprocessors/#pyaki.preprocessors.UrineOutputPreProcessor","title":"<code>UrineOutputPreProcessor</code>","text":"<p>               Bases: <code>Preprocessor</code></p> <p>Preprocessor for processing the urine output dataset.</p> <p>Parameters:</p> Name Type Description Default <code>stay_identifier</code> <code>str</code> <p>The column name that identifies stays or admissions in the dataset.</p> <code>\"stay_id\"</code> <code>time_identifier</code> <code>str</code> <p>The column name that identifies the timestamp or time variable in the dataset.</p> <code>\"charttime\"</code> <code>urineoutput_column</code> <code>str</code> <p>The column name that represents the urine output values in the dataset.</p> <code>\"urineoutput\"</code> <code>interpolate</code> <code>bool</code> <p>Flag indicating whether to perform interpolation on missing values.</p> <code>True</code> <code>threshold</code> <code>int</code> <p>The threshold value for limiting the interpolation range.</p> <code>6</code> Source code in <code>pyaki/preprocessors.py</code> <pre><code>class UrineOutputPreProcessor(Preprocessor):\n    \"\"\"\n    Preprocessor for processing the urine output dataset.\n\n    Parameters\n    ----------\n    stay_identifier : str, default: \"stay_id\"\n        The column name that identifies stays or admissions in the dataset.\n    time_identifier : str, default: \"charttime\"\n        The column name that identifies the timestamp or time variable in the dataset.\n    urineoutput_column : str, default: \"urineoutput\"\n        The column name that represents the urine output values in the dataset.\n    interpolate : bool, default: True\n        Flag indicating whether to perform interpolation on missing values.\n    threshold : int, default: 6\n        The threshold value for limiting the interpolation range.\n    \"\"\"\n\n    def __init__(\n        self,\n        stay_identifier: str = \"stay_id\",\n        time_identifier: str = \"charttime\",\n        urineoutput_column: str = \"urineoutput\",\n        interpolate: bool = True,\n        threshold: int = 6,\n    ) -&gt; None:\n        super().__init__(stay_identifier, time_identifier)\n        self._interpolate: bool = interpolate\n        self._threshold: int = threshold\n        self._urineoutput_column: str = urineoutput_column\n\n    @dataset_as_df(df=DatasetType.URINEOUTPUT)\n    @df_to_dataset(DatasetType.URINEOUTPUT)\n    def process(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Process the urine output dataset by resampling, interpolating missing values, and applying threshold-based adjustments.\n\n        Parameters\n        ----------\n        df : pd.DataFrame\n            The input urine output dataset as a pandas DataFrame.\n\n        Returns\n        -------\n        pd.DataFrame\n            The processed urine output dataset as a pandas DataFrame.\n        \"\"\"\n\n        df = df.groupby(self._stay_identifier).resample(\"1h\").sum()  # type: ignore\n        df[df[self._urineoutput_column] == 0] = None\n\n        if not self._interpolate:\n            return df\n\n        mask = df[self._urineoutput_column].isnull()\n        df[self._urineoutput_column] /= (\n            (mask.cumsum() - mask.cumsum().where(~mask).ffill().fillna(0))\n            .shift(1)\n            .clip(upper=self._threshold)\n            .add(1)\n            .fillna(1)\n        )\n        return df.bfill(limit=self._threshold)\n</code></pre>"},{"location":"reference/pyaki/preprocessors/#pyaki.preprocessors.UrineOutputPreProcessor.process","title":"<code>process(df)</code>","text":"<p>Process the urine output dataset by resampling, interpolating missing values, and applying threshold-based adjustments.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input urine output dataset as a pandas DataFrame.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The processed urine output dataset as a pandas DataFrame.</p> Source code in <code>pyaki/preprocessors.py</code> <pre><code>@dataset_as_df(df=DatasetType.URINEOUTPUT)\n@df_to_dataset(DatasetType.URINEOUTPUT)\ndef process(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Process the urine output dataset by resampling, interpolating missing values, and applying threshold-based adjustments.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The input urine output dataset as a pandas DataFrame.\n\n    Returns\n    -------\n    pd.DataFrame\n        The processed urine output dataset as a pandas DataFrame.\n    \"\"\"\n\n    df = df.groupby(self._stay_identifier).resample(\"1h\").sum()  # type: ignore\n    df[df[self._urineoutput_column] == 0] = None\n\n    if not self._interpolate:\n        return df\n\n    mask = df[self._urineoutput_column].isnull()\n    df[self._urineoutput_column] /= (\n        (mask.cumsum() - mask.cumsum().where(~mask).ffill().fillna(0))\n        .shift(1)\n        .clip(upper=self._threshold)\n        .add(1)\n        .fillna(1)\n    )\n    return df.bfill(limit=self._threshold)\n</code></pre>"},{"location":"reference/pyaki/probes/","title":"probes","text":"<p>This module contains the Probe abstract base class and its subclasses, used for probing for the different KDIGO criteria.</p>"},{"location":"reference/pyaki/probes/#pyaki.probes.AbsoluteCreatinineProbe","title":"<code>AbsoluteCreatinineProbe</code>","text":"<p>               Bases: <code>AbstractCreatinineProbe</code></p> <p>Probe class for absolute creatinine criterion, according to KDIGO criteria.</p> <p>This class represents a probe that calculates AKI stages according to absolute rises in creatinine, according to the KDIGO criteria. It extends the <code>AbstractCreCreatinineProbe</code> class.</p> <p>Attributes:</p> Name Type Description <code>RESNAME</code> <code>str</code> <p>The name of the resulting stage column.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>The name of the column containing creatinine values.</p> <code>\"creat\"</code> <code>baseline_constant_column</code> <code>str</code> <p>The name of the column containing constant baseline values.</p> <code>\"baseline_constant\"</code> <code>patient_weight_column</code> <code>str</code> <p>The name of the column containing the patient's weight.</p> <code>\"weight\"</code> <code>patient_age_column</code> <code>str</code> <p>The name of the column containing the patient's age.</p> <code>\"age\"</code> <code>patient_height_column</code> <code>str</code> <p>The name of the column containing the patient's height.</p> <code>\"height\"</code> <code>patient_gender_column</code> <code>str</code> <p>The name of the column containing the patient's gender.</p> <code>\"gender\"</code> <code>baseline_timeframe</code> <code>str</code> <p>The timeframe for calculating the baseline values.</p> <code>\"2d\"</code> <code>expected_clearance</code> <code>float</code> <p>The expected creatinine clearance rate.</p> <code>72</code> <code>method</code> <code>CreatinineBaselineMethod</code> <p>The method for calculating the creatinine baseline values.</p> <code>CreatinineBaselineMethod.ROLLING_MIN</code> Example <pre><code>&gt;&gt;&gt; probe = AbsoluteCreatinineProbe(column=\"creatinine\", baseline_timeframe=\"7d\", method=CreatinineMethod.MIN)\n... df_result = probe.probe(df)\n</code></pre> Source code in <code>pyaki/probes.py</code> <pre><code>class AbsoluteCreatinineProbe(AbstractCreatinineProbe):\n    \"\"\"\n    Probe class for absolute creatinine criterion, according to KDIGO criteria.\n\n    This class represents a probe that calculates AKI stages according to absolute rises in creatinine, according to the KDIGO criteria.\n    It extends the `AbstractCreCreatinineProbe` class.\n\n    Attributes\n    ----------\n    RESNAME : str\n        The name of the resulting stage column.\n\n    Parameters\n    ----------\n    column : str, default: \"creat\"\n        The name of the column containing creatinine values.\n    baseline_constant_column : str, default: \"baseline_constant\"\n        The name of the column containing constant baseline values.\n    patient_weight_column : str, default: \"weight\"\n        The name of the column containing the patient's weight.\n    patient_age_column : str, default: \"age\"\n        The name of the column containing the patient's age.\n    patient_height_column : str, default: \"height\"\n        The name of the column containing the patient's height.\n    patient_gender_column : str, default: \"gender\"\n        The name of the column containing the patient's gender.\n    baseline_timeframe : str, default: \"2d\"\n        The timeframe for calculating the baseline values.\n    expected_clearance : float, default: 72\n        The expected creatinine clearance rate.\n    method : CreatinineBaselineMethod, default: CreatinineBaselineMethod.ROLLING_MIN\n        The method for calculating the creatinine baseline values.\n\n    Example\n    -------\n    ```pycon\n    &gt;&gt;&gt; probe = AbsoluteCreatinineProbe(column=\"creatinine\", baseline_timeframe=\"7d\", method=CreatinineMethod.MIN)\n    ... df_result = probe.probe(df)\n    ```\n    \"\"\"\n\n    RESNAME = \"abs_creatinine_stage\"\n\n    def __init__(\n        self,\n        column: str = \"creat\",\n        baseline_constant_column: str = \"baseline_constant\",\n        patient_weight_column: str = \"weight\",\n        patient_age_column: str = \"age\",\n        patient_height_column: str = \"height\",\n        patient_gender_column: str = \"gender\",\n        baseline_timeframe: str = \"2d\",\n        expected_clearance: float = 72,\n        method: CreatinineBaselineMethod = CreatinineBaselineMethod.ROLLING_MIN,\n    ) -&gt; None:\n        super().__init__(\n            column=column,\n            baseline_constant_column=baseline_constant_column,\n            patient_weight_column=patient_weight_column,\n            patient_age_column=patient_age_column,\n            patient_height_column=patient_height_column,\n            patient_gender_column=patient_gender_column,\n            baseline_timeframe=baseline_timeframe,\n            expected_clearance=expected_clearance,\n            method=method,\n        )\n\n    @dataset_as_df(df=DatasetType.CREATININE, patient=DatasetType.DEMOGRAPHICS)\n    @df_to_dataset(DatasetType.CREATININE)\n    def probe(\n        self,\n        df: pd.DataFrame,\n        patient: pd.DataFrame,\n        **kwargs: Any,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Perform KDIGO stage calculation based on absolute creatinine elevations on the provided DataFrame.\n\n        This method calculates the KDIGO stage based on the provided DataFrame\n        and the configured baseline values. It calculates the stage according to KDIGO criteria.\n\n        Parameters\n        ----------\n        df : pd.DataFrame\n            The DataFrame containing the creatinine data. It should have a column\n            with the name specified in the `column` attribute of the probe.\n        patient : pd.DataFrame\n            The DataFrame containing patient information. Should contain the patients weight in kg and the age.\n\n        Returns\n        -------\n        pd.DataFrame\n            The modified DataFrame with the absolute creatinine stage column added.\n        \"\"\"\n        df = df.copy()\n\n        baseline_values: pd.Series = self.creatinine_baseline(df, patient)\n\n        df.loc[:, self.RESNAME] = 0\n        df.loc[approx_gte((df[self._column] - baseline_values), 0.3), self.RESNAME] = 1\n        df.loc[approx_gte(df[self._column], 4), self.RESNAME] = 3\n\n        df.loc[pd.isna(df[self._column]), self.RESNAME] = np.nan\n\n        return df\n</code></pre>"},{"location":"reference/pyaki/probes/#pyaki.probes.AbsoluteCreatinineProbe.probe","title":"<code>probe(df, patient, **kwargs)</code>","text":"<p>Perform KDIGO stage calculation based on absolute creatinine elevations on the provided DataFrame.</p> <p>This method calculates the KDIGO stage based on the provided DataFrame and the configured baseline values. It calculates the stage according to KDIGO criteria.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame containing the creatinine data. It should have a column with the name specified in the <code>column</code> attribute of the probe.</p> required <code>patient</code> <code>DataFrame</code> <p>The DataFrame containing patient information. Should contain the patients weight in kg and the age.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The modified DataFrame with the absolute creatinine stage column added.</p> Source code in <code>pyaki/probes.py</code> <pre><code>@dataset_as_df(df=DatasetType.CREATININE, patient=DatasetType.DEMOGRAPHICS)\n@df_to_dataset(DatasetType.CREATININE)\ndef probe(\n    self,\n    df: pd.DataFrame,\n    patient: pd.DataFrame,\n    **kwargs: Any,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Perform KDIGO stage calculation based on absolute creatinine elevations on the provided DataFrame.\n\n    This method calculates the KDIGO stage based on the provided DataFrame\n    and the configured baseline values. It calculates the stage according to KDIGO criteria.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The DataFrame containing the creatinine data. It should have a column\n        with the name specified in the `column` attribute of the probe.\n    patient : pd.DataFrame\n        The DataFrame containing patient information. Should contain the patients weight in kg and the age.\n\n    Returns\n    -------\n    pd.DataFrame\n        The modified DataFrame with the absolute creatinine stage column added.\n    \"\"\"\n    df = df.copy()\n\n    baseline_values: pd.Series = self.creatinine_baseline(df, patient)\n\n    df.loc[:, self.RESNAME] = 0\n    df.loc[approx_gte((df[self._column] - baseline_values), 0.3), self.RESNAME] = 1\n    df.loc[approx_gte(df[self._column], 4), self.RESNAME] = 3\n\n    df.loc[pd.isna(df[self._column]), self.RESNAME] = np.nan\n\n    return df\n</code></pre>"},{"location":"reference/pyaki/probes/#pyaki.probes.AbstractCreatinineProbe","title":"<code>AbstractCreatinineProbe</code>","text":"<p>               Bases: <code>Probe</code></p> <p>Abstract base class representing a creatinine probe.</p> <p>This class serves as an abstract base class for creatinine probes. It extends the <code>Probe</code> class and provides common functionality and attributes for creatinine probe implementations.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>The name of the column containing creatinine values.</p> <code>\"creat\"</code> <code>baseline_constant_column</code> <code>str</code> <p>The name of the column containing constant baseline values.</p> <code>\"baseline_constant\"</code> <code>patient_weight_column</code> <code>str</code> <p>The name of the column containing the patient's weight.</p> <code>\"weight\"</code> <code>patient_age_column</code> <code>str</code> <p>The name of the column containing the patient's age.</p> <code>\"age\"</code> <code>patient_height_column</code> <code>str</code> <p>The name of the column containing the patient's height.</p> <code>\"height\"</code> <code>patient_gender_column</code> <code>str</code> <p>The name of the column containing the patient's gender.</p> <code>\"gender\"</code> <code>baseline_timeframe</code> <code>str</code> <p>The timeframe for calculating the baseline values.</p> <code>\"7d\"</code> <code>expected_clearance</code> <code>float</code> <p>The expected creatinine clearance rate.</p> <code>72</code> <code>method</code> <code>CreatinineBaselineMethod</code> <p>The method for calculating the creatinine baseline values.</p> <code>CreatinineBaselineMethod.ROLLING_MIN</code> Example <pre><code>&gt;&gt;&gt; class MyCreatinineProbe(AbstractCreCreatinineProbe):\n...     def __init__(self, column=\"creatinine\", baseline_timeframe=\"7d\", method=CreatinineBaselineMethod.MIN):\n...         super().__init__(column, baseline_timeframe, method)\n...         # Additional initialization\n...\n...     def probe(self, df, **kwargs):\n...         # Probe implementation specific to the derived class\n</code></pre> Source code in <code>pyaki/probes.py</code> <pre><code>class AbstractCreatinineProbe(Probe, metaclass=ABCMeta):\n    \"\"\"\n    Abstract base class representing a creatinine probe.\n\n    This class serves as an abstract base class for creatinine probes.\n    It extends the `Probe` class and provides common functionality and attributes\n    for creatinine probe implementations.\n\n    Parameters\n    ----------\n    column : str, default: \"creat\"\n        The name of the column containing creatinine values.\n    baseline_constant_column : str, default: \"baseline_constant\"\n        The name of the column containing constant baseline values.\n    patient_weight_column : str, default: \"weight\"\n        The name of the column containing the patient's weight.\n    patient_age_column : str, default: \"age\"\n        The name of the column containing the patient's age.\n    patient_height_column : str, default: \"height\"\n        The name of the column containing the patient's height.\n    patient_gender_column : str, default: \"gender\"\n        The name of the column containing the patient's gender.\n    baseline_timeframe : str, default: \"7d\"\n        The timeframe for calculating the baseline values.\n    expected_clearance : float, default: 72\n        The expected creatinine clearance rate.\n    method : CreatinineBaselineMethod, default: CreatinineBaselineMethod.ROLLING_MIN\n        The method for calculating the creatinine baseline values.\n\n    Example\n    -------\n    ```pycon\n    &gt;&gt;&gt; class MyCreatinineProbe(AbstractCreCreatinineProbe):\n    ...     def __init__(self, column=\"creatinine\", baseline_timeframe=\"7d\", method=CreatinineBaselineMethod.MIN):\n    ...         super().__init__(column, baseline_timeframe, method)\n    ...         # Additional initialization\n    ...\n    ...     def probe(self, df, **kwargs):\n    ...         # Probe implementation specific to the derived class\n    ```\n    \"\"\"\n\n    def __init__(\n        self,\n        column: str = \"creat\",\n        baseline_constant_column: str = \"baseline_constant\",\n        patient_weight_column: str = \"weight\",\n        patient_age_column: str = \"age\",\n        patient_height_column: str = \"height\",\n        patient_gender_column: str = \"gender\",\n        baseline_timeframe: str = \"7d\",\n        expected_clearance: float = 72,\n        method: CreatinineBaselineMethod = CreatinineBaselineMethod.ROLLING_MIN,\n    ) -&gt; None:\n        super().__init__()\n\n        self._column: str = column\n        self._baseline_constant_column: str = baseline_constant_column\n        self._patient_weight_column: str = patient_weight_column\n        self._patient_age_column: str = patient_age_column\n        self._patient_height_column: str = patient_height_column\n        self._patient_gender_column: str = patient_gender_column\n\n        self._baseline_timeframe: str = baseline_timeframe\n        self._expected_clearance: float = expected_clearance\n        self._method: CreatinineBaselineMethod = method\n\n    def creatinine_baseline(self, df: pd.DataFrame, patient: pd.DataFrame) -&gt; pd.Series:\n        \"\"\"\n        Calculate the creatinine baseline values.\n\n        This method calculates the creatinine baseline values based on the configured\n        parameters and the provided DataFrame.\n\n        Parameters\n        ----------\n        df : pd.DataFrame\n            The DataFrame containing the creatinine data.\n\n        Returns\n        -------\n        pd.Series\n            The calculated creatinine baseline values.\n        \"\"\"\n        if isinstance(df.index, PeriodIndex):\n            df.index = df.index.to_timestamp()\n\n        if self._method == CreatinineBaselineMethod.ROLLING_FIRST:\n            return (\n                df[df[self._column] &gt; 0]\n                .rolling(self._baseline_timeframe)\n                .agg(lambda rows: rows.iloc[0])\n                .resample(\"1h\")\n                .first()\n                .ffill()[self._column]\n            )\n\n        if self._method == CreatinineBaselineMethod.ROLLING_MIN:\n            return (\n                df[df[self._column] &gt; 0]\n                .rolling(self._baseline_timeframe)\n                .min()\n                .resample(\"1h\")\n                .min()\n                .ffill()[self._column]\n            )\n        if self._method == CreatinineBaselineMethod.ROLLING_MEAN:\n            return (\n                df[df[self._column] &gt; 0]\n                .rolling(self._baseline_timeframe)\n                .mean()\n                .resample(\"1h\")\n                .mean()\n                .ffill()[self._column]\n            )\n\n        if self._method == CreatinineBaselineMethod.FIXED_MIN:\n            values: pd.Series = (\n                df[df[self._column] &gt; 0]\n                .rolling(self._baseline_timeframe)\n                .min()\n                .resample(\"1h\")\n                .min()\n                .ffill()[self._column]\n            )\n            min_value: pd.DatetimeIndex = values[\n                values.index &lt;= (values.index[0] + pd.Timedelta(self._baseline_timeframe))\n            ].min()  # calculate min value for first 7 days\n            values[\n                values.index &gt; (values.index[0] + pd.Timedelta(self._baseline_timeframe))\n            ] = min_value  # set all values after first 7 days to min value\n\n            return values\n\n        if self._method == CreatinineBaselineMethod.FIXED_MEAN:\n            time_delta = pd.to_timedelta(self._baseline_timeframe)\n            end_time = df.index[0] + time_delta\n            value = df[df.index &lt;= end_time][self._column].mean()\n            values = self._to_df_length(df, value)\n            return values\n\n        if self._method == CreatinineBaselineMethod.OVERALL_FIRST:\n            value = df[df[self._column] &gt; 0].iloc[0][self._column]\n            values = self._to_df_length(df, value)\n            return values\n\n        if self._method == CreatinineBaselineMethod.OVERALL_MIN:\n            value = df[df[self._column] &gt; 0][self._column].min()\n            values = self._to_df_length(df, value)\n            return values\n\n        if self._method == CreatinineBaselineMethod.OVERALL_MEAN:\n            value = df[df[self._column] &gt; 0][self._column].mean()\n            values = self._to_df_length(df, value)\n            return values\n\n        if self._method == CreatinineBaselineMethod.CONSTANT:\n            if self._baseline_constant_column not in patient:\n                raise ValueError(\n                    \"Baseline constant method requires baseline constant values. Please provide a pd.Series containing baseline values for creatinine.\"\n                )\n\n            return pd.Series(\n                [patient[self._baseline_constant_column]] * len(df),\n                index=df.index,\n                name=self._column,\n            )\n\n        if self._method == CreatinineBaselineMethod.CALCULATED:\n            columns = [\n                self._patient_weight_column,\n                self._patient_age_column,\n                self._patient_height_column,\n                self._patient_gender_column,\n            ]\n            for column in columns:\n                if column not in patient:\n                    raise ValueError(\n                        f\"Calculated baseline method requires patient {column}. Please provide a pd.Series containing patient {column}.\"\n                    )\n\n            weight = patient[self._patient_weight_column]\n            height = patient[self._patient_height_column]\n            gender = patient[self._patient_gender_column]\n            age = patient[self._patient_age_column]\n\n            ibw = (50.0 if gender == \"M\" else 45.5) + 2.3 * height / 2.54 - 60\n            abw = ibw + 0.4 * (weight - ibw)\n\n            # fmt: off\n            return pd.Series(\n                [\n                    ((140 - age) * abw * (1 if gender == \"M\" else 0.85)) /\n                    (70 * self._expected_clearance)\n                ] * len(df),\n                index=df.index,\n                name=self._column,\n            )\n            # fmt: on\n\n    def _to_df_length(self, df: pd.DataFrame, value: float) -&gt; pd.Series:\n        \"\"\"\n        Helper function to create a series, the same length as the data frame.\n\n        Parameters\n        ----------\n        df : pd.DataFrame\n            The DataFrame to match the length of.\n        value : float\n            The value to fill the series with.\n\n        Returns\n        -------\n        pd.Series\n            The series with the same length as the DataFrame.\n        \"\"\"\n        values = pd.Series(\n            [value] * len(df),\n            index=df.index,\n            name=self._column,\n        )\n        return values\n</code></pre>"},{"location":"reference/pyaki/probes/#pyaki.probes.AbstractCreatinineProbe.creatinine_baseline","title":"<code>creatinine_baseline(df, patient)</code>","text":"<p>Calculate the creatinine baseline values.</p> <p>This method calculates the creatinine baseline values based on the configured parameters and the provided DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame containing the creatinine data.</p> required <p>Returns:</p> Type Description <code>Series</code> <p>The calculated creatinine baseline values.</p> Source code in <code>pyaki/probes.py</code> <pre><code>def creatinine_baseline(self, df: pd.DataFrame, patient: pd.DataFrame) -&gt; pd.Series:\n    \"\"\"\n    Calculate the creatinine baseline values.\n\n    This method calculates the creatinine baseline values based on the configured\n    parameters and the provided DataFrame.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The DataFrame containing the creatinine data.\n\n    Returns\n    -------\n    pd.Series\n        The calculated creatinine baseline values.\n    \"\"\"\n    if isinstance(df.index, PeriodIndex):\n        df.index = df.index.to_timestamp()\n\n    if self._method == CreatinineBaselineMethod.ROLLING_FIRST:\n        return (\n            df[df[self._column] &gt; 0]\n            .rolling(self._baseline_timeframe)\n            .agg(lambda rows: rows.iloc[0])\n            .resample(\"1h\")\n            .first()\n            .ffill()[self._column]\n        )\n\n    if self._method == CreatinineBaselineMethod.ROLLING_MIN:\n        return (\n            df[df[self._column] &gt; 0]\n            .rolling(self._baseline_timeframe)\n            .min()\n            .resample(\"1h\")\n            .min()\n            .ffill()[self._column]\n        )\n    if self._method == CreatinineBaselineMethod.ROLLING_MEAN:\n        return (\n            df[df[self._column] &gt; 0]\n            .rolling(self._baseline_timeframe)\n            .mean()\n            .resample(\"1h\")\n            .mean()\n            .ffill()[self._column]\n        )\n\n    if self._method == CreatinineBaselineMethod.FIXED_MIN:\n        values: pd.Series = (\n            df[df[self._column] &gt; 0]\n            .rolling(self._baseline_timeframe)\n            .min()\n            .resample(\"1h\")\n            .min()\n            .ffill()[self._column]\n        )\n        min_value: pd.DatetimeIndex = values[\n            values.index &lt;= (values.index[0] + pd.Timedelta(self._baseline_timeframe))\n        ].min()  # calculate min value for first 7 days\n        values[\n            values.index &gt; (values.index[0] + pd.Timedelta(self._baseline_timeframe))\n        ] = min_value  # set all values after first 7 days to min value\n\n        return values\n\n    if self._method == CreatinineBaselineMethod.FIXED_MEAN:\n        time_delta = pd.to_timedelta(self._baseline_timeframe)\n        end_time = df.index[0] + time_delta\n        value = df[df.index &lt;= end_time][self._column].mean()\n        values = self._to_df_length(df, value)\n        return values\n\n    if self._method == CreatinineBaselineMethod.OVERALL_FIRST:\n        value = df[df[self._column] &gt; 0].iloc[0][self._column]\n        values = self._to_df_length(df, value)\n        return values\n\n    if self._method == CreatinineBaselineMethod.OVERALL_MIN:\n        value = df[df[self._column] &gt; 0][self._column].min()\n        values = self._to_df_length(df, value)\n        return values\n\n    if self._method == CreatinineBaselineMethod.OVERALL_MEAN:\n        value = df[df[self._column] &gt; 0][self._column].mean()\n        values = self._to_df_length(df, value)\n        return values\n\n    if self._method == CreatinineBaselineMethod.CONSTANT:\n        if self._baseline_constant_column not in patient:\n            raise ValueError(\n                \"Baseline constant method requires baseline constant values. Please provide a pd.Series containing baseline values for creatinine.\"\n            )\n\n        return pd.Series(\n            [patient[self._baseline_constant_column]] * len(df),\n            index=df.index,\n            name=self._column,\n        )\n\n    if self._method == CreatinineBaselineMethod.CALCULATED:\n        columns = [\n            self._patient_weight_column,\n            self._patient_age_column,\n            self._patient_height_column,\n            self._patient_gender_column,\n        ]\n        for column in columns:\n            if column not in patient:\n                raise ValueError(\n                    f\"Calculated baseline method requires patient {column}. Please provide a pd.Series containing patient {column}.\"\n                )\n\n        weight = patient[self._patient_weight_column]\n        height = patient[self._patient_height_column]\n        gender = patient[self._patient_gender_column]\n        age = patient[self._patient_age_column]\n\n        ibw = (50.0 if gender == \"M\" else 45.5) + 2.3 * height / 2.54 - 60\n        abw = ibw + 0.4 * (weight - ibw)\n\n        # fmt: off\n        return pd.Series(\n            [\n                ((140 - age) * abw * (1 if gender == \"M\" else 0.85)) /\n                (70 * self._expected_clearance)\n            ] * len(df),\n            index=df.index,\n            name=self._column,\n        )\n</code></pre>"},{"location":"reference/pyaki/probes/#pyaki.probes.CreatinineBaselineMethod","title":"<code>CreatinineBaselineMethod</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enumeration class representing different methods for creatinine baseline calculations.</p> <p>This class defines the available methods for calculating creatinine values. It is a subclass of the <code>StrEnum</code> class, which is a string-based enumeration. The available methods are <code>MIN</code> and <code>FIRST</code>.</p> <p>Attributes:</p> Name Type Description <code>ROLLING_MIN</code> <code>str</code> <p>Minimum of a rolling window following the timepoint of observation is used as baseline.</p> <code>ROLLING_FIRST</code> <code>str</code> <p>First value of a rolling window following the timepoint of observation is used as baseline.</p> <code>ROLLING_MEAN</code> <code>str</code> <p>Mean of a rolling window following the timepoint of observation is used as baseline.</p> <code>FIXED_MIN</code> <code>str</code> <p>Minimum of the first n days of observation is used as baseline.</p> <code>FIXED_MEAN</code> <code>str</code> <p>Mean of the first n days of observation is used as baseline.</p> <code>OVERALL_FIRST</code> <code>str</code> <p>First observed value is used as baseline.</p> <code>OVERALL_MEAN</code> <code>str</code> <p>Mean of all observed values is used as baseline.</p> <code>OVERALL_MIN</code> <code>str</code> <p>Minimum of all observed values is used as baseline.</p> <code>CONSTANT</code> <code>str</code> <p>A constant value is used as baseline.</p> <code>CALCULATED</code> <code>str</code> <p>A calculated value is used as baseline, based off of the Cockcroft-Gault-Formula using the Adjusted Body Weight.</p> Source code in <code>pyaki/probes.py</code> <pre><code>class CreatinineBaselineMethod(StrEnum):\n    \"\"\"\n    Enumeration class representing different methods for creatinine baseline calculations.\n\n    This class defines the available methods for calculating creatinine values.\n    It is a subclass of the `StrEnum` class, which is a string-based enumeration.\n    The available methods are `MIN` and `FIRST`.\n\n    Attributes\n    ----------\n    ROLLING_MIN : str\n        Minimum of a rolling window following the timepoint of observation is used as baseline.\n    ROLLING_FIRST : str\n        First value of a rolling window following the timepoint of observation is used as baseline.\n    ROLLING_MEAN : str\n        Mean of a rolling window following the timepoint of observation is used as baseline.\n    FIXED_MIN : str\n        Minimum of the first n days of observation is used as baseline.\n    FIXED_MEAN : str\n        Mean of the first n days of observation is used as baseline.\n    OVERALL_FIRST : str\n        First observed value is used as baseline.\n    OVERALL_MEAN : str\n        Mean of all observed values is used as baseline.\n    OVERALL_MIN : str\n        Minimum of all observed values is used as baseline.\n    CONSTANT : str\n        A constant value is used as baseline.\n    CALCULATED : str\n        A calculated value is used as baseline, based off of the Cockcroft-Gault-Formula using the Adjusted Body Weight.\n    \"\"\"\n\n    ROLLING_MIN = auto()\n    ROLLING_FIRST = auto()\n    ROLLING_MEAN = auto()\n    FIXED_MIN = auto()\n    FIXED_MEAN = auto()\n    OVERALL_FIRST = auto()\n    OVERALL_MEAN = auto()\n    OVERALL_MIN = auto()\n    CONSTANT = auto()\n    CALCULATED = auto()\n</code></pre>"},{"location":"reference/pyaki/probes/#pyaki.probes.Probe","title":"<code>Probe</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class representing a data analysis probe.</p> <p>This class serves as an abstract base class (ABC) for data analysis probes. It declares the abstract method <code>probe()</code> that must be implemented by its subclasses. The <code>RESNAME</code> attribute can be overridden by subclasses to specify the name of the result column generated by the probe.</p> <p>Attributes:</p> Name Type Description <code>RESNAME</code> <code>str</code> <p>The name of the result column generated by the probe.</p> <p>Methods:</p> Name Description <code>probe</code> <p>Abstract method to be implemented by subclasses. It performs data analysis on the provided datasets and returns a DataFrame with the analysis results.</p> Example <pre><code>&gt;&gt;&gt; class MyProbe(Probe):\n...     RESNAME = \"my_result\"\n...\n...     def probe(self, datasets: list[Dataset], **kwargs) -&gt; pd.DataFrame:\n...         # Implementation of the probe's analysis...\n...\n... my_probe = MyProbe()\n... result_df = my_probe.probe(datasets=my_datasets, additional_arg=value)\n</code></pre> Source code in <code>pyaki/probes.py</code> <pre><code>class Probe(ABC):\n    \"\"\"\n    Abstract base class representing a data analysis probe.\n\n    This class serves as an abstract base class (ABC) for data analysis probes.\n    It declares the abstract method `probe()` that must be implemented by its subclasses.\n    The `RESNAME` attribute can be overridden by subclasses to specify the name of the\n    result column generated by the probe.\n\n    Attributes\n    ----------\n    RESNAME : str\n        The name of the result column generated by the probe.\n\n    Methods\n    -------\n    probe()\n        Abstract method to be implemented by subclasses. It performs data analysis on the\n        provided datasets and returns a DataFrame with the analysis results.\n\n    Example\n    -------\n    ```pycon\n    &gt;&gt;&gt; class MyProbe(Probe):\n    ...     RESNAME = \"my_result\"\n    ...\n    ...     def probe(self, datasets: list[Dataset], **kwargs) -&gt; pd.DataFrame:\n    ...         # Implementation of the probe's analysis...\n    ...\n    ... my_probe = MyProbe()\n    ... result_df = my_probe.probe(datasets=my_datasets, additional_arg=value)\n    ```\n    \"\"\"\n\n    RESNAME: str = \"\"  # name of the column that will be added to the dataframe\n\n    def probe(self, datasets: list[Dataset], **kwargs: Any) -&gt; list[Dataset]:\n        \"\"\"\n        Abstract method to be implemented by subclasses.\n\n        This method performs data analysis on the provided datasets and returns a DataFrame\n        with the analysis results. Subclasses must override this method.\n\n        Parameters\n        ----------\n        datasets : list[Dataset]\n            A list of Dataset objects containing the input data.\n        **kwargs\n            Additional keyword arguments for the analysis.\n\n        Returns\n        -------\n        pd.DataFrame\n            The DataFrame containing the analysis results.\n        \"\"\"\n        raise NotImplementedError()\n</code></pre>"},{"location":"reference/pyaki/probes/#pyaki.probes.Probe.probe","title":"<code>probe(datasets, **kwargs)</code>","text":"<p>Abstract method to be implemented by subclasses.</p> <p>This method performs data analysis on the provided datasets and returns a DataFrame with the analysis results. Subclasses must override this method.</p> <p>Parameters:</p> Name Type Description Default <code>datasets</code> <code>list[Dataset]</code> <p>A list of Dataset objects containing the input data.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for the analysis.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The DataFrame containing the analysis results.</p> Source code in <code>pyaki/probes.py</code> <pre><code>def probe(self, datasets: list[Dataset], **kwargs: Any) -&gt; list[Dataset]:\n    \"\"\"\n    Abstract method to be implemented by subclasses.\n\n    This method performs data analysis on the provided datasets and returns a DataFrame\n    with the analysis results. Subclasses must override this method.\n\n    Parameters\n    ----------\n    datasets : list[Dataset]\n        A list of Dataset objects containing the input data.\n    **kwargs\n        Additional keyword arguments for the analysis.\n\n    Returns\n    -------\n    pd.DataFrame\n        The DataFrame containing the analysis results.\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"reference/pyaki/probes/#pyaki.probes.RRTProbe","title":"<code>RRTProbe</code>","text":"<p>               Bases: <code>Probe</code></p> <p>Probe class for RRT.</p> <p>This class represents a probe that calculates RRT. It will return a KDIGO stage 3 if the patient is on RRT at any time during the ICU stay. It will return 0 otherwise.</p> <p>Attributes:</p> Name Type Description <code>RESNAME</code> <code>str</code> <p>The name of the resulting stage column.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>The name of the column containing the RRT data.</p> <code>\"rrt_status\"</code> Source code in <code>pyaki/probes.py</code> <pre><code>class RRTProbe(Probe):\n    \"\"\"\n    Probe class for RRT.\n\n    This class represents a probe that calculates RRT. It will return a KDIGO stage 3 if the patient is on RRT at any time during the ICU stay. It will return 0 otherwise.\n\n    Attributes\n    ----------\n    RESNAME : str\n        The name of the resulting stage column.\n\n    Parameters\n    ----------\n    column : str, default: \"rrt_status\"\n        The name of the column containing the RRT data.\n    \"\"\"\n\n    RESNAME = \"rrt_stage\"\n\n    def __init__(self, column: str = \"rrt_status\") -&gt; None:\n        super().__init__()\n\n        self._column: str = column\n\n    @dataset_as_df(df=DatasetType.RRT)\n    @df_to_dataset(DatasetType.RRT)\n    def probe(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Perform calculation of RRT on the provided DataFrame.\n\n        Parameters\n        ----------\n        df : pd.DataFrame\n            The DataFrame containing the RRT data. It should have a column\n            with the name specified in the `column` attribute of the probe.\n\n        Returns\n        -------\n        pd.DataFrame\n            The modified DataFrame with the RRT stage column added.\n        \"\"\"\n        df = df.copy()\n\n        df.loc[:, self.RESNAME] = 0\n        df.loc[df[self._column] == 1, self.RESNAME] = 3\n\n        # transfer nans\n        df.loc[pd.isna(df[self._column]), self.RESNAME] = np.nan\n\n        return df\n</code></pre>"},{"location":"reference/pyaki/probes/#pyaki.probes.RRTProbe.probe","title":"<code>probe(df)</code>","text":"<p>Perform calculation of RRT on the provided DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame containing the RRT data. It should have a column with the name specified in the <code>column</code> attribute of the probe.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The modified DataFrame with the RRT stage column added.</p> Source code in <code>pyaki/probes.py</code> <pre><code>@dataset_as_df(df=DatasetType.RRT)\n@df_to_dataset(DatasetType.RRT)\ndef probe(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Perform calculation of RRT on the provided DataFrame.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The DataFrame containing the RRT data. It should have a column\n        with the name specified in the `column` attribute of the probe.\n\n    Returns\n    -------\n    pd.DataFrame\n        The modified DataFrame with the RRT stage column added.\n    \"\"\"\n    df = df.copy()\n\n    df.loc[:, self.RESNAME] = 0\n    df.loc[df[self._column] == 1, self.RESNAME] = 3\n\n    # transfer nans\n    df.loc[pd.isna(df[self._column]), self.RESNAME] = np.nan\n\n    return df\n</code></pre>"},{"location":"reference/pyaki/probes/#pyaki.probes.RelativeCreatinineProbe","title":"<code>RelativeCreatinineProbe</code>","text":"<p>               Bases: <code>AbstractCreatinineProbe</code></p> <p>Probe class for relative creatinine measurements.</p> <p>This class represents a probe calculates KDIGO stages based on relative creatinine elevations.</p> <p>Attributes:</p> Name Type Description <code>RESNAME</code> <code>str</code> <p>The name of the resulting stage column.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>The name of the column containing creatinine values.</p> <code>\"creat\"</code> <code>baseline_constant_column</code> <code>str</code> <p>The name of the column containing constant baseline values.</p> <code>\"baseline_constant\"</code> <code>patient_weight_column</code> <code>str</code> <p>The name of the column containing the patient's weight.</p> <code>\"weight\"</code> <code>patient_age_column</code> <code>str</code> <p>The name of the column containing the patient's age.</p> <code>\"age\"</code> <code>patient_height_column</code> <code>str</code> <p>The name of the column containing the patient's height.</p> <code>\"height\"</code> <code>patient_gender_column</code> <code>str</code> <p>The name of the column containing the patient's gender.</p> <code>\"gender\"</code> <code>baseline_timeframe</code> <code>str</code> <p>The timeframe for calculating the baseline values.</p> <code>\"7d\"</code> <code>expected_clearance</code> <code>float</code> <p>The expected creatinine clearance rate.</p> <code>72</code> <code>method</code> <code>CreatinineBaselineMethod</code> <p>The method for calculating the creatinine baseline values.</p> <code>CreatinineBaselineMethod.ROLLING_MIN</code> Example <pre><code>&gt;&gt;&gt; probe = RelativeCreatinineProbe(column=\"creatinine\", baseline_timeframe=\"7d\", method=CreatinineBaselineMethod.MIN)\n... df_result = probe.probe(df)\n</code></pre> Source code in <code>pyaki/probes.py</code> <pre><code>class RelativeCreatinineProbe(AbstractCreatinineProbe):\n    \"\"\"\n    Probe class for relative creatinine measurements.\n\n    This class represents a probe calculates KDIGO stages based on relative creatinine elevations.\n\n    Attributes\n    ----------\n    RESNAME : str\n        The name of the resulting stage column.\n\n    Parameters\n    ----------\n    column : str, default: \"creat\"\n        The name of the column containing creatinine values.\n    baseline_constant_column : str, default: \"baseline_constant\"\n        The name of the column containing constant baseline values.\n    patient_weight_column : str, default: \"weight\"\n        The name of the column containing the patient's weight.\n    patient_age_column : str, default: \"age\"\n        The name of the column containing the patient's age.\n    patient_height_column : str, default: \"height\"\n        The name of the column containing the patient's height.\n    patient_gender_column : str, default: \"gender\"\n        The name of the column containing the patient's gender.\n    baseline_timeframe : str, default: \"7d\"\n        The timeframe for calculating the baseline values.\n    expected_clearance : float, default: 72\n        The expected creatinine clearance rate.\n    method : CreatinineBaselineMethod, default: CreatinineBaselineMethod.ROLLING_MIN\n        The method for calculating the creatinine baseline values.\n\n    Example\n    -------\n    ```pycon\n    &gt;&gt;&gt; probe = RelativeCreatinineProbe(column=\"creatinine\", baseline_timeframe=\"7d\", method=CreatinineBaselineMethod.MIN)\n    ... df_result = probe.probe(df)\n    ```\n    \"\"\"\n\n    RESNAME = \"rel_creatinine_stage\"\n\n    @dataset_as_df(df=DatasetType.CREATININE, patient=DatasetType.DEMOGRAPHICS)\n    @df_to_dataset(DatasetType.CREATININE)\n    def probe(self, df: pd.DataFrame, patient: pd.DataFrame, **kwargs: Any) -&gt; pd.DataFrame:\n        \"\"\"\n        Perform calculation of relative creatinine elevations on the provided DataFrame.\n\n        This method calculates the relative creatinine stage based on the provided DataFrame\n        and the configured baseline values. It modifies the DataFrame by adding the relative\n        creatinine stage column with appropriate values based on the calculations.\n\n        Parameters\n        ----------\n        df : pd.DataFrame\n            The DataFrame containing the creatinine data. It should have a column\n            with the name specified in the `column` attribute of the probe.\n        patient : pd.DataFrame\n            The DataFrame containing patient information. Should contain the patients weight in kg and the age.\n\n        Returns\n        -------\n        pd.DataFrame\n            The modified DataFrame with the relative creatinine stage column added.\n        \"\"\"\n        df = df.copy()\n\n        baseline_values: pd.Series = self.creatinine_baseline(df, patient)\n\n        df.loc[:, self.RESNAME] = 0\n        df.loc[approx_gte((df[self._column] / baseline_values), 1.5), self.RESNAME] = 1.0\n        df.loc[approx_gte((df[self._column] / baseline_values), 2), self.RESNAME] = 2\n        df.loc[approx_gte((df[self._column] / baseline_values), 3), self.RESNAME] = 3\n\n        df.loc[pd.isna(df[self._column]), self.RESNAME] = np.nan\n\n        return df\n</code></pre>"},{"location":"reference/pyaki/probes/#pyaki.probes.RelativeCreatinineProbe.probe","title":"<code>probe(df, patient, **kwargs)</code>","text":"<p>Perform calculation of relative creatinine elevations on the provided DataFrame.</p> <p>This method calculates the relative creatinine stage based on the provided DataFrame and the configured baseline values. It modifies the DataFrame by adding the relative creatinine stage column with appropriate values based on the calculations.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame containing the creatinine data. It should have a column with the name specified in the <code>column</code> attribute of the probe.</p> required <code>patient</code> <code>DataFrame</code> <p>The DataFrame containing patient information. Should contain the patients weight in kg and the age.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The modified DataFrame with the relative creatinine stage column added.</p> Source code in <code>pyaki/probes.py</code> <pre><code>@dataset_as_df(df=DatasetType.CREATININE, patient=DatasetType.DEMOGRAPHICS)\n@df_to_dataset(DatasetType.CREATININE)\ndef probe(self, df: pd.DataFrame, patient: pd.DataFrame, **kwargs: Any) -&gt; pd.DataFrame:\n    \"\"\"\n    Perform calculation of relative creatinine elevations on the provided DataFrame.\n\n    This method calculates the relative creatinine stage based on the provided DataFrame\n    and the configured baseline values. It modifies the DataFrame by adding the relative\n    creatinine stage column with appropriate values based on the calculations.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The DataFrame containing the creatinine data. It should have a column\n        with the name specified in the `column` attribute of the probe.\n    patient : pd.DataFrame\n        The DataFrame containing patient information. Should contain the patients weight in kg and the age.\n\n    Returns\n    -------\n    pd.DataFrame\n        The modified DataFrame with the relative creatinine stage column added.\n    \"\"\"\n    df = df.copy()\n\n    baseline_values: pd.Series = self.creatinine_baseline(df, patient)\n\n    df.loc[:, self.RESNAME] = 0\n    df.loc[approx_gte((df[self._column] / baseline_values), 1.5), self.RESNAME] = 1.0\n    df.loc[approx_gte((df[self._column] / baseline_values), 2), self.RESNAME] = 2\n    df.loc[approx_gte((df[self._column] / baseline_values), 3), self.RESNAME] = 3\n\n    df.loc[pd.isna(df[self._column]), self.RESNAME] = np.nan\n\n    return df\n</code></pre>"},{"location":"reference/pyaki/probes/#pyaki.probes.UrineOutputMethod","title":"<code>UrineOutputMethod</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enumeration class representing different methods for urine output calculations</p> <p>Attributes:</p> Name Type Description <code>STRICT</code> <code>str</code> <p>Strict method for urine output calculations. Using this method, the urine output stage is calculated based on the maximum urine output in the past 6, 12, and 24 hours.</p> <code>MEAN</code> <code>str</code> <p>Mean method for urine output calculations.</p> Source code in <code>pyaki/probes.py</code> <pre><code>class UrineOutputMethod(StrEnum):\n    \"\"\"\n    Enumeration class representing different methods for urine output calculations\n\n    Attributes\n    ----------\n    STRICT : str\n        Strict method for urine output calculations. Using this method, the urine output stage is calculated based on the maximum urine output in the past 6, 12, and 24 hours.\n    MEAN : str\n        Mean method for urine output calculations.\n    \"\"\"\n\n    STRICT = auto()\n    MEAN = auto()\n</code></pre>"},{"location":"reference/pyaki/probes/#pyaki.probes.UrineOutputProbe","title":"<code>UrineOutputProbe</code>","text":"<p>               Bases: <code>Probe</code></p> <p>Subclass of Probe representing a probe calculating KDIGO stages according to urine output.</p> <p>This class specializes the abstract base class <code>Probe</code> to perform calculations of KDIGO stages based on urine output. Common KDIGO criteria apply. It overrides the <code>RESNAME</code> attribute to set the name of the result column. The <code>probe()</code> method performs urine output analysis on the provided DataFrame and returns a modified DataFrame with a column containing the appropriate KDIGO stage, according to urine output, added.</p> <p>Attributes:</p> Name Type Description <code>RESNAME</code> <code>str</code> <p>The name of the result column representing urine output stage.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>The name of the column representing urine output in the DataFrame.</p> <code>\"urineoutput\"</code> <code>patient_weight_column</code> <code>str</code> <p>The name of the column representing the patient's weight in the patient DataFrame.</p> <code>\"weight\"</code> <code>anuria_limit</code> <code>float</code> <p>The anuria limit for urine output calculations.</p> <code>0.1</code> Example <pre><code>&gt;&gt;&gt; probe = UrineOutputProbe(column=\"urineoutput\", anuria_limit=0.1)\n... result_df = probe.probe(df=my_dataframe, patient=patient_df)\n</code></pre> Source code in <code>pyaki/probes.py</code> <pre><code>class UrineOutputProbe(Probe):\n    \"\"\"\n    Subclass of Probe representing a probe calculating KDIGO stages according to urine output.\n\n    This class specializes the abstract base class `Probe` to perform calculations of KDIGO stages based on urine output. Common KDIGO criteria apply.\n    It overrides the `RESNAME` attribute to set the name of the result column.\n    The `probe()` method performs urine output analysis on the provided DataFrame and returns a modified DataFrame\n    with a column containing the appropriate KDIGO stage, according to urine output, added.\n\n    Attributes\n    ----------\n    RESNAME : str\n        The name of the result column representing urine output stage.\n\n    Parameters\n    ----------\n    column : str, default: \"urineoutput\"\n        The name of the column representing urine output in the DataFrame.\n    patient_weight_column : str, default: \"weight\"\n        The name of the column representing the patient's weight in the patient DataFrame.\n    anuria_limit : float, default: 0.1\n        The anuria limit for urine output calculations.\n\n    Example\n    -------\n    ```pycon\n    &gt;&gt;&gt; probe = UrineOutputProbe(column=\"urineoutput\", anuria_limit=0.1)\n    ... result_df = probe.probe(df=my_dataframe, patient=patient_df)\n    ```\n    \"\"\"\n\n    RESNAME = \"urineoutput_stage\"\n\n    def __init__(\n        self,\n        column: str = \"urineoutput\",\n        patient_weight_column: str = \"weight\",\n        anuria_limit: float = 0.1,\n        method: UrineOutputMethod = UrineOutputMethod.MEAN,\n    ) -&gt; None:\n        super().__init__()\n\n        self._column: str = column\n        self._patient_weight_column: str = patient_weight_column\n\n        self._anuria_limit: float = anuria_limit\n        self._method: UrineOutputMethod = method\n\n    @dataset_as_df(df=DatasetType.URINEOUTPUT, patient=DatasetType.DEMOGRAPHICS)\n    @df_to_dataset(DatasetType.URINEOUTPUT)\n    def probe(\n        self,\n        df: pd.DataFrame,\n        patient: pd.DataFrame,\n        **kwargs: Any,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Perform urine output analysis on the provided DataFrame.\n\n        This method calculates the KDIGO stage according to urine output based on the provided DataFrame and patient information DataFrame.\n        It modifies the DataFrame by adding the urine output stage column with appropriate values based on the calculations.\n\n        Parameters\n        ----------\n        df : pd.DataFrame\n            The DataFrame containing the urine output data. We expect the DataFrame to contain urine output values in ml, sampled hourly.\n        patient : pd.DataFrame\n            The DataFrame containing patient information. Should contain the patients weight in kg.\n\n        Returns\n        -------\n        pd.DataFrame\n            The modified DataFrame with the urine output stage column added.\n        \"\"\"\n        if self._patient_weight_column not in patient:\n            raise ValueError(\"Missing weight for stay\")\n\n        df = df.copy()\n\n        weight: pd.Series = patient[self._patient_weight_column]\n        # fmt: off\n        df.loc[:, self.RESNAME] = np.nan  # set all urineoutput_stage values to NaN\n        df.loc[df.rolling(6).min()[self._column] &gt;= 0, self.RESNAME] = 0\n\n        if self._method == UrineOutputMethod.STRICT:\n            df.loc[(df.rolling(6).max()[self._column] / weight) &lt; 0.5, self.RESNAME] = 1\n            df.loc[(df.rolling(12).max()[self._column] / weight) &lt; 0.5, self.RESNAME] = 2\n            df.loc[(df.rolling(24).max()[self._column] / weight) &lt; 0.3, self.RESNAME] = 3\n            df.loc[(df.rolling(12).max()[self._column] / weight) &lt; self._anuria_limit, self.RESNAME] = 3\n        elif self._method == UrineOutputMethod.MEAN:\n            df.loc[(df.rolling(6).mean()[self._column] / weight) &lt; 0.5, self.RESNAME] = 1\n            df.loc[(df.rolling(12).mean()[self._column] / weight) &lt; 0.5, self.RESNAME] = 2\n            df.loc[(df.rolling(24).mean()[self._column] / weight) &lt; 0.3, self.RESNAME] = 3\n            df.loc[(df.rolling(12).mean()[self._column] / weight) &lt; self._anuria_limit, self.RESNAME] = 3\n        else:\n            raise ValueError(f\"Invalid method: {self._method}\")\n        # fmt: on\n\n        df.loc[pd.isna(df[self._column]), self.RESNAME] = np.nan\n\n        return df\n</code></pre>"},{"location":"reference/pyaki/probes/#pyaki.probes.UrineOutputProbe.probe","title":"<code>probe(df, patient, **kwargs)</code>","text":"<p>Perform urine output analysis on the provided DataFrame.</p> <p>This method calculates the KDIGO stage according to urine output based on the provided DataFrame and patient information DataFrame. It modifies the DataFrame by adding the urine output stage column with appropriate values based on the calculations.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The DataFrame containing the urine output data. We expect the DataFrame to contain urine output values in ml, sampled hourly.</p> required <code>patient</code> <code>DataFrame</code> <p>The DataFrame containing patient information. Should contain the patients weight in kg.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The modified DataFrame with the urine output stage column added.</p> Source code in <code>pyaki/probes.py</code> <pre><code>@dataset_as_df(df=DatasetType.URINEOUTPUT, patient=DatasetType.DEMOGRAPHICS)\n@df_to_dataset(DatasetType.URINEOUTPUT)\ndef probe(\n    self,\n    df: pd.DataFrame,\n    patient: pd.DataFrame,\n    **kwargs: Any,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Perform urine output analysis on the provided DataFrame.\n\n    This method calculates the KDIGO stage according to urine output based on the provided DataFrame and patient information DataFrame.\n    It modifies the DataFrame by adding the urine output stage column with appropriate values based on the calculations.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The DataFrame containing the urine output data. We expect the DataFrame to contain urine output values in ml, sampled hourly.\n    patient : pd.DataFrame\n        The DataFrame containing patient information. Should contain the patients weight in kg.\n\n    Returns\n    -------\n    pd.DataFrame\n        The modified DataFrame with the urine output stage column added.\n    \"\"\"\n    if self._patient_weight_column not in patient:\n        raise ValueError(\"Missing weight for stay\")\n\n    df = df.copy()\n\n    weight: pd.Series = patient[self._patient_weight_column]\n    # fmt: off\n    df.loc[:, self.RESNAME] = np.nan  # set all urineoutput_stage values to NaN\n    df.loc[df.rolling(6).min()[self._column] &gt;= 0, self.RESNAME] = 0\n\n    if self._method == UrineOutputMethod.STRICT:\n        df.loc[(df.rolling(6).max()[self._column] / weight) &lt; 0.5, self.RESNAME] = 1\n        df.loc[(df.rolling(12).max()[self._column] / weight) &lt; 0.5, self.RESNAME] = 2\n        df.loc[(df.rolling(24).max()[self._column] / weight) &lt; 0.3, self.RESNAME] = 3\n        df.loc[(df.rolling(12).max()[self._column] / weight) &lt; self._anuria_limit, self.RESNAME] = 3\n    elif self._method == UrineOutputMethod.MEAN:\n        df.loc[(df.rolling(6).mean()[self._column] / weight) &lt; 0.5, self.RESNAME] = 1\n        df.loc[(df.rolling(12).mean()[self._column] / weight) &lt; 0.5, self.RESNAME] = 2\n        df.loc[(df.rolling(24).mean()[self._column] / weight) &lt; 0.3, self.RESNAME] = 3\n        df.loc[(df.rolling(12).mean()[self._column] / weight) &lt; self._anuria_limit, self.RESNAME] = 3\n    else:\n        raise ValueError(f\"Invalid method: {self._method}\")\n    # fmt: on\n\n    df.loc[pd.isna(df[self._column]), self.RESNAME] = np.nan\n\n    return df\n</code></pre>"},{"location":"reference/pyaki/utils/","title":"utils","text":"<p>This module contains the utility functions and classes used in the pyaki package.</p>"},{"location":"reference/pyaki/utils/#pyaki.utils.Dataset","title":"<code>Dataset</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Named tuple representing a dataset.</p> <p>This class represents a dataset consisting of a dataset type and a DataFrame. It is defined as a named tuple, which is an immutable data structure with named fields. The <code>dataset_type</code> field is of type <code>DatasetType</code> and represents the type of the dataset. The <code>df</code> field is of type <code>pd.DataFrame</code> and represents the actual data stored in a pandas DataFrame object.</p> <p>Attributes:</p> Name Type Description <code>dataset_type</code> <code>DatasetType</code> <p>The type of the dataset.</p> <code>df</code> <code>DataFrame</code> <p>The DataFrame object containing the dataset.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dataset = Dataset(dataset_type=DatasetType.URINEOUTPUT, df=my_dataframe)\n</code></pre> Source code in <code>pyaki/utils.py</code> <pre><code>class Dataset(NamedTuple):\n    \"\"\"\n    Named tuple representing a dataset.\n\n    This class represents a dataset consisting of a dataset type and a DataFrame.\n    It is defined as a named tuple, which is an immutable data structure with\n    named fields. The `dataset_type` field is of type `DatasetType` and represents\n    the type of the dataset. The `df` field is of type `pd.DataFrame` and represents\n    the actual data stored in a pandas DataFrame object.\n\n    Attributes\n    ----------\n    dataset_type : DatasetType\n        The type of the dataset.\n    df : pd.DataFrame\n        The DataFrame object containing the dataset.\n\n    Examples\n    --------\n    ```pycon\n    &gt;&gt;&gt; dataset = Dataset(dataset_type=DatasetType.URINEOUTPUT, df=my_dataframe)\n    ```\n    \"\"\"\n\n    dataset_type: DatasetType\n    df: pd.DataFrame\n</code></pre>"},{"location":"reference/pyaki/utils/#pyaki.utils.DatasetType","title":"<code>DatasetType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Enumeration class representing different types of datasets.</p> <p>Attributes:</p> Name Type Description <code>URINEOUTPUT</code> <code>str</code> <p>The urine output dataset.</p> <code>CREATININE</code> <code>str</code> <p>The creatinine dataset.</p> <code>DEMOGRAPHICS</code> <code>str</code> <p>The demographics dataset.</p> <code>RRT</code> <code>str</code> <p>The renal replacement therapy dataset.</p> Source code in <code>pyaki/utils.py</code> <pre><code>class DatasetType(StrEnum):\n    \"\"\"\n    Enumeration class representing different types of datasets.\n\n    Attributes\n    ----------\n    URINEOUTPUT : str\n        The urine output dataset.\n    CREATININE : str\n        The creatinine dataset.\n    DEMOGRAPHICS : str\n        The demographics dataset.\n    RRT : str\n        The renal replacement therapy dataset.\n    \"\"\"\n\n    URINEOUTPUT = auto()\n    CREATININE = auto()\n    DEMOGRAPHICS = auto()\n    RRT = auto()\n</code></pre>"},{"location":"reference/pyaki/utils/#pyaki.utils.approx_gte","title":"<code>approx_gte(x, y)</code>","text":"<p>Check if x is greater than or approximately equal to y.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Series</code> <p>The series to compare.</p> required <code>y</code> <code>Series or float</code> <p>The series or float to compare with.</p> required Source code in <code>pyaki/utils.py</code> <pre><code>def approx_gte(x: pd.Series, y: pd.Series | float) -&gt; bool | np.ndarray:\n    \"\"\"\n    Check if x is greater than or approximately equal to y.\n\n    Parameters\n    ----------\n    x : pd.Series\n        The series to compare.\n    y : pd.Series or float\n        The series or float to compare with.\n    \"\"\"\n    return np.logical_or(np.asarray(x &gt;= y), np.isclose(x, y))\n</code></pre>"},{"location":"reference/pyaki/utils/#pyaki.utils.dataset_as_df","title":"<code>dataset_as_df(**mapping)</code>","text":"<p>Decorator factory for methods that process datasets with dataframes.</p> <p>This decorator is intended to be used with methods in a class that handle datasets consisting of dataframes. It allows you to specify a mapping of dataset types to corresponding dataframe names. The decorator then replaces the dataframes of the specified types with the results of the decorated method.</p> <p>Parameters:</p> Name Type Description Default <code>**mapping</code> <code>dict[str, DatasetType]</code> <p>A mapping of dataset type names to their corresponding <code>DatasetType</code>. Dataset types not found in this mapping will be ignored.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>decorator</code> <code>Callable</code> <p>A decorator that can be applied to methods in a class. The decorated method is expected to accept a list of <code>Dataset</code> objects and optional additional arguments and keyword arguments.</p> <p>Examples:</p> <p>Suppose you have a method <code>process_data</code> that takes a list of <code>Dataset</code> objects and a <code>mapping</code> as specified in the decorator:</p> <pre><code>&gt;&gt;&gt; @dataset_as_df(data=DatasetType.DATA, labels=DatasetType.LABELS)\n... def process_data(self, data: pd.DataFrame, labels: pd.DataFrame):\n...     # Your data processing logic here\n...     return processed_data, labels\n</code></pre> <p>When you call <code>process_data</code> with a list of <code>Dataset</code> objects containing data and labels, the decorator will automatically replace the dataframes based on the mapping and pass them to the method:</p> <pre><code>&gt;&gt;&gt; processed_datasets = my_instance.process_data(datasets)\n</code></pre> Source code in <code>pyaki/utils.py</code> <pre><code>def dataset_as_df(**mapping: DatasetType) -&gt; Callable:\n    \"\"\"\n    Decorator factory for methods that process datasets with dataframes.\n\n    This decorator is intended to be used with methods in a class that handle datasets\n    consisting of dataframes. It allows you to specify a mapping of dataset types to\n    corresponding dataframe names. The decorator then replaces the dataframes of the\n    specified types with the results of the decorated method.\n\n    Parameters\n    ----------\n    **mapping : dict[str, DatasetType]\n        A mapping of dataset type names to their corresponding `DatasetType`.\n        Dataset types not found in this mapping will be ignored.\n\n    Returns\n    -------\n    decorator : Callable\n        A decorator that can be applied to methods in a class. The decorated\n        method is expected to accept a list of `Dataset` objects and optional\n        additional arguments and keyword arguments.\n\n    Examples\n    --------\n    Suppose you have a method `process_data` that takes a list of `Dataset` objects\n    and a `mapping` as specified in the decorator:\n\n    ```pycon\n    &gt;&gt;&gt; @dataset_as_df(data=DatasetType.DATA, labels=DatasetType.LABELS)\n    ... def process_data(self, data: pd.DataFrame, labels: pd.DataFrame):\n    ...     # Your data processing logic here\n    ...     return processed_data, labels\n    ```\n\n    When you call `process_data` with a list of `Dataset` objects containing data\n    and labels, the decorator will automatically replace the dataframes based on\n    the mapping and pass them to the method:\n\n    ```pycon\n    &gt;&gt;&gt; processed_datasets = my_instance.process_data(datasets)\n    ```\n    \"\"\"\n    # swap keys and values in the mapping\n    in_mapping: dict[DatasetType, str] = {}\n    for k, v in mapping.items():\n        in_mapping[cast(DatasetType, v)] = k\n\n    # in_mapping: Dict[DatasetType, str] = {v: k for k, v in mapping.items()}\n\n    def decorator(func: Callable) -&gt; Callable:\n        @wraps(func)\n        def wrapper(self: Any, datasets: list[Dataset], *args: Any, **kwargs: Any) -&gt; list[Dataset]:\n            # map the dataset types to corresponding DataFrames\n            _mapping: dict[str, pd.DataFrame] = {\n                in_mapping[dtype]: df for dtype, df in datasets if dtype in in_mapping.keys()\n            }\n            # check if all datasets are mapped, otherwise return the original datasets\n            if len(in_mapping) != len(_mapping):\n                logger.warning(\n                    \"Skip %s because one or more datasets are missing to probe\",\n                    self.__class__.__name__,\n                )\n                return datasets\n\n            # call the wrapped function with the converted DataFrames\n            _dtype, _df = func(self, *args, **_mapping, **kwargs)\n\n            # return the updated datasets\n            return [Dataset(dtype, _df if dtype == _dtype else df) for dtype, df in datasets]\n\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"reference/pyaki/utils/#pyaki.utils.df_to_dataset","title":"<code>df_to_dataset(dtype)</code>","text":"<p>Decorator that converts a DataFrame into a dataset with the specified type.</p> <p>This decorator is intended to be used with a method that returns a DataFrame. It wraps the method and converts the returned DataFrame into a dataset object with the specified type. The converted dataset is then returned.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DatasetType</code> <p>The DatasetType enum value representing the type of the dataset.</p> required <p>Returns:</p> Name Type Description <code>decorator</code> <code>Callable</code> <p>A decorated function that takes the original arguments, performs the wrapped function, converts the returned DataFrame into a Dataset object with the specified type, and returns the converted dataset.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; @df_to_dataset(DatasetType.URINEOUTPUT)\n... def process_dataframe(self, *args: list, **kwargs: dict) -&gt; pd.DataFrame:\n...     # Process the DataFrame\n...     ...\n</code></pre> Source code in <code>pyaki/utils.py</code> <pre><code>def df_to_dataset(dtype: DatasetType) -&gt; Callable:\n    \"\"\"\n    Decorator that converts a DataFrame into a dataset with the specified type.\n\n    This decorator is intended to be used with a method that returns a DataFrame.\n    It wraps the method and converts the returned DataFrame into a dataset object\n    with the specified type. The converted dataset is then returned.\n\n    Parameters\n    ----------\n    dtype : DatasetType\n        The DatasetType enum value representing the type of the dataset.\n\n    Returns\n    -------\n    decorator : Callable\n        A decorated function that takes the original arguments, performs the wrapped\n        function, converts the returned DataFrame into a Dataset object with the\n        specified type, and returns the converted dataset.\n\n    Examples\n    --------\n    ```pycon\n    &gt;&gt;&gt; @df_to_dataset(DatasetType.URINEOUTPUT)\n    ... def process_dataframe(self, *args: list, **kwargs: dict) -&gt; pd.DataFrame:\n    ...     # Process the DataFrame\n    ...     ...\n    ```\n    \"\"\"\n\n    def decorator(func: Callable) -&gt; Callable:\n        @wraps(func)\n        def wrapper(self: Any, *args: Any, **kwargs: Any) -&gt; Dataset:\n            return Dataset(dtype, func(self, *args, **kwargs))\n\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"reference/pyaki/bin/","title":"bin","text":"<p>This module contains cli commands for pyaki.</p> <p>To use the CLI you can use the <code>pyaki-cli</code> command. For more information on how to use the CLI, run <code>pyaki-cli --help</code>.</p> <pre><code>Usage: pyaki-cli [OPTIONS] PATH\n\nCLI tool to process AKI stages from time series data.\n\nArguments:\n    *    path      TEXT  [default: None] [required]\n\nOptions:\n    --urineoutput-file         TEXT  [default: urineoutput.csv]\n    --rrt-file                 TEXT  [default: rrt.csv]\n    --demographics-file        TEXT  [default: demographics.csv]\n    --help                           Show this message and exit.\n</code></pre>"},{"location":"reference/pyaki/bin/process_aki_stages/","title":"process_aki_stages","text":"<p>pyaki CLI tool to process AKI stages from time series data.</p>"},{"location":"reference/pyaki/bin/process_aki_stages/#pyaki.bin.process_aki_stages.main","title":"<code>main(path, urineoutput_file='urineoutput.csv', creatinine_file='creatinine.csv', rrt_file='rrt.csv', demographics_file='demographics.csv')</code>","text":"<p>CLI tool to process AKI stages from time series data.</p> <p>CLI tool to process AKI stages from time series data. The tool expects the following files to be present in the given path: urineoutput.csv, creatinine.csv, rrt.csv, demographics.csv.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the folder containing the data files.</p> required <code>urineoutput_file</code> <code>str</code> <p>Name of the file containing urine output data.</p> <code>\"urineoutput.csv\"</code> <code>creatinine_file</code> <code>str</code> <p>name of the file containing creatinine data.</p> <code>\"creatinine.csv\"</code> <code>rrt_file</code> <code>str</code> <p>Name of the file containing rrt data.</p> <code>\"rrt.csv\"</code> <code>demographics_file</code> <code>str</code> <p>Name of the file containing demographic data of the patient like the patients weight.</p> <code>\"demographics.csv\"</code> Source code in <code>pyaki/bin/process_aki_stages.py</code> <pre><code>def main(\n    path: str,\n    urineoutput_file: str = \"urineoutput.csv\",\n    creatinine_file: str = \"creatinine.csv\",\n    rrt_file: str = \"rrt.csv\",\n    demographics_file: str = \"demographics.csv\",\n) -&gt; None:\n    \"\"\"\n    CLI tool to process AKI stages from time series data.\n\n    CLI tool to process AKI stages from time series data. The tool expects\n    the following files to be present in the given path: urineoutput.csv, creatinine.csv, rrt.csv, demographics.csv.\n\n    Parameters\n    ----------\n    path : str\n        Path to the folder containing the data files.\n    urineoutput_file : str, default: \"urineoutput.csv\"\n        Name of the file containing urine output data.\n    creatinine_file : str, default: \"creatinine.csv\"\n        name of the file containing creatinine data.\n    rrt_file : str, default: \"rrt.csv\"\n        Name of the file containing rrt data.\n    demographics_file : str, default: \"demographics.csv\"\n        Name of the file containing demographic data of the patient like the patients weight.\n    \"\"\"\n    root_dir = Path(path)\n    datasets = []\n\n    if (ou_file := root_dir / urineoutput_file).is_file():\n        datasets.append(Dataset(DatasetType.URINEOUTPUT, pd.read_csv(ou_file)))\n\n    if (scr_file := root_dir / creatinine_file).is_file():\n        datasets.append(Dataset(DatasetType.CREATININE, pd.read_csv(scr_file)))\n\n    if (_rrt_file := root_dir / rrt_file).is_file():\n        datasets.append(Dataset(DatasetType.RRT, pd.read_csv(_rrt_file)))\n\n    if (demo_file := root_dir / demographics_file).is_file():\n        datasets.append(Dataset(DatasetType.DEMOGRAPHICS, pd.read_csv(demo_file)))\n\n    ana: Analyser = Analyser(datasets)\n    ana.process_stays().to_csv(root_dir / \"aki.csv\")\n</code></pre>"},{"location":"reference/pyaki/bin/process_aki_stages/#pyaki.bin.process_aki_stages.run","title":"<code>run()</code>","text":"<p>Run the CLI tool</p> Source code in <code>pyaki/bin/process_aki_stages.py</code> <pre><code>def run() -&gt; None:\n    \"\"\"Run the CLI tool\"\"\"\n    typer.run(main)\n</code></pre>"}]}